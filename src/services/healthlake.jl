# This file is auto-generated by AWSMetadata.jl
using AWS
using AWS.AWSServices: healthlake
using AWS.Compat
using AWS.UUIDs

# Julia syntax for service-level optional parameters to the AWS request syntax
const SERVICE_PARAMETER_MAP = AWS.LittleDict("job_name" => "JobName", "job_status" => "JobStatus", "max_results" => "MaxResults", "next_token" => "NextToken", "submitted_after" => "SubmittedAfter", "submitted_before" => "SubmittedBefore", "client_token" => "ClientToken", "datastore_name" => "DatastoreName", "preload_data_config" => "PreloadDataConfig", "sse_configuration" => "SseConfiguration", "tags" => "Tags", "datastore_id" => "DatastoreId", "filter" => "Filter")

"""
    create_fhirdatastore(datastore_type_version; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a Data Store that can ingest and export FHIR formatted data.

# Arguments
- `datastore_type_version`: The FHIR version of the Data Store. The only supported version
  is R4.

# Keyword Parameters
- `client_token`: Optional user provided token used for ensuring idempotency.
- `datastore_name`: The user generated name for the Data Store.
- `preload_data_config`: Optional parameter to preload data upon creation of the Data
  Store. Currently, the only supported preloaded data is synthetic data generated from
  Synthea.
- `sse_configuration`:  The server-side encryption key configuration for a customer
  provided encryption key specified for creating a Data Store.
- `tags`:  Resource tags that are applied to a Data Store when it is created.
"""
function create_fhirdatastore(DatastoreTypeVersion; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(SERVICE_PARAMETER_MAP, kwargs)
    return healthlake("CreateFHIRDatastore", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatastoreTypeVersion"=>DatastoreTypeVersion, "client_token"=>string(uuid4())), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_fhirdatastore(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes a Data Store.

# Keyword Parameters
- `datastore_id`:  The AWS-generated ID for the Data Store to be deleted.
"""
function delete_fhirdatastore(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(SERVICE_PARAMETER_MAP, kwargs)
    return healthlake("DeleteFHIRDatastore", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    describe_fhirdatastore(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Gets the properties associated with the FHIR Data Store, including the Data Store ID, Data
Store ARN, Data Store name, Data Store status, created at, Data Store type version, and
Data Store endpoint.

# Keyword Parameters
- `datastore_id`: The AWS-generated Data Store id. This is part of the
  ‘CreateFHIRDatastore’ output.
"""
function describe_fhirdatastore(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(SERVICE_PARAMETER_MAP, kwargs)
    return healthlake("DescribeFHIRDatastore", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    describe_fhirexport_job(datastore_id, job_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Displays the properties of a FHIR export job, including the ID, ARN, name, and the status
of the job.

# Arguments
- `datastore_id`: The AWS generated ID for the Data Store from which files are being
  exported from for an export job.
- `job_id`: The AWS generated ID for an export job.

"""
function describe_fhirexport_job(DatastoreId, JobId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(SERVICE_PARAMETER_MAP, kwargs)
    return healthlake("DescribeFHIRExportJob", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatastoreId"=>DatastoreId, "JobId"=>JobId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    describe_fhirimport_job(datastore_id, job_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Displays the properties of a FHIR import job, including the ID, ARN, name, and the status
of the job.

# Arguments
- `datastore_id`: The AWS-generated ID of the Data Store.
- `job_id`: The AWS-generated job ID.

"""
function describe_fhirimport_job(DatastoreId, JobId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(SERVICE_PARAMETER_MAP, kwargs)
    return healthlake("DescribeFHIRImportJob", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatastoreId"=>DatastoreId, "JobId"=>JobId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_fhirdatastores(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Lists all FHIR Data Stores that are in the user’s account, regardless of Data Store
status.

# Keyword Parameters
- `filter`: Lists all filters associated with a FHIR Data Store request.
- `max_results`: The maximum number of Data Stores returned in a single page of a
  ListFHIRDatastoresRequest call.
- `next_token`: Fetches the next page of Data Stores when results are paginated.
"""
function list_fhirdatastores(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(SERVICE_PARAMETER_MAP, kwargs)
    return healthlake("ListFHIRDatastores", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_fhirexport_jobs(datastore_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

 Lists all FHIR export jobs associated with an account and their statuses.

# Arguments
- `datastore_id`:  This parameter limits the response to the export job with the specified
  Data Store ID.

# Keyword Parameters
- `job_name`:  This parameter limits the response to the export job with the specified job
  name.
- `job_status`:  This parameter limits the response to the export jobs with the specified
  job status.
- `max_results`:  This parameter limits the number of results returned for a
  ListFHIRExportJobs to a maximum quantity specified by the user.
- `next_token`:  A pagination token used to identify the next page of results to return for
  a ListFHIRExportJobs query.
- `submitted_after`:  This parameter limits the response to FHIR export jobs submitted
  after a user specified date.
- `submitted_before`:  This parameter limits the response to FHIR export jobs submitted
  before a user specified date.
"""
function list_fhirexport_jobs(DatastoreId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(SERVICE_PARAMETER_MAP, kwargs)
    return healthlake("ListFHIRExportJobs", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatastoreId"=>DatastoreId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_fhirimport_jobs(datastore_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

 Lists all FHIR import jobs associated with an account and their statuses.

# Arguments
- `datastore_id`:  This parameter limits the response to the import job with the specified
  Data Store ID.

# Keyword Parameters
- `job_name`:  This parameter limits the response to the import job with the specified job
  name.
- `job_status`:  This parameter limits the response to the import job with the specified
  job status.
- `max_results`:  This parameter limits the number of results returned for a
  ListFHIRImportJobs to a maximum quantity specified by the user.
- `next_token`:  A pagination token used to identify the next page of results to return for
  a ListFHIRImportJobs query.
- `submitted_after`:  This parameter limits the response to FHIR import jobs submitted
  after a user specified date.
- `submitted_before`:  This parameter limits the response to FHIR import jobs submitted
  before a user specified date.
"""
function list_fhirimport_jobs(DatastoreId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(SERVICE_PARAMETER_MAP, kwargs)
    return healthlake("ListFHIRImportJobs", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatastoreId"=>DatastoreId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_tags_for_resource(resource_arn; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

 Returns a list of all existing tags associated with a Data Store.

# Arguments
- `resource_arn`:  The Amazon Resource Name(ARN) of the Data Store for which tags are being
  added.

"""
function list_tags_for_resource(ResourceARN; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(SERVICE_PARAMETER_MAP, kwargs)
    return healthlake("ListTagsForResource", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ResourceARN"=>ResourceARN), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    start_fhirexport_job(client_token, data_access_role_arn, datastore_id, output_data_config; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Begins a FHIR export job.

# Arguments
- `client_token`: An optional user provided token used for ensuring idempotency.
- `data_access_role_arn`: The Amazon Resource Name used during the initiation of the job.
- `datastore_id`: The AWS generated ID for the Data Store from which files are being
  exported for an export job.
- `output_data_config`: The output data configuration that was supplied when the export job
  was created.

# Keyword Parameters
- `job_name`: The user generated name for an export job.
"""
function start_fhirexport_job(ClientToken, DataAccessRoleArn, DatastoreId, OutputDataConfig; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(SERVICE_PARAMETER_MAP, kwargs)
    return healthlake("StartFHIRExportJob", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ClientToken"=>ClientToken, "DataAccessRoleArn"=>DataAccessRoleArn, "DatastoreId"=>DatastoreId, "OutputDataConfig"=>OutputDataConfig), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    start_fhirimport_job(client_token, data_access_role_arn, datastore_id, input_data_config, job_output_data_config; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Begins a FHIR Import job.

# Arguments
- `client_token`: Optional user provided token used for ensuring idempotency.
- `data_access_role_arn`: The Amazon Resource Name (ARN) that gives Amazon HealthLake
  access permission.
- `datastore_id`: The AWS-generated Data Store ID.
- `input_data_config`: The input properties of the FHIR Import job in the StartFHIRImport
  job request.
- `job_output_data_config`:

# Keyword Parameters
- `job_name`: The name of the FHIR Import job in the StartFHIRImport job request.
"""
function start_fhirimport_job(ClientToken, DataAccessRoleArn, DatastoreId, InputDataConfig, JobOutputDataConfig; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(SERVICE_PARAMETER_MAP, kwargs)
    return healthlake("StartFHIRImportJob", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ClientToken"=>ClientToken, "DataAccessRoleArn"=>DataAccessRoleArn, "DatastoreId"=>DatastoreId, "InputDataConfig"=>InputDataConfig, "JobOutputDataConfig"=>JobOutputDataConfig), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    tag_resource(resource_arn, tags; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

 Adds a user specifed key and value tag to a Data Store.

# Arguments
- `resource_arn`:  The Amazon Resource Name(ARN)that gives Amazon HealthLake access to the
  Data Store which tags are being added to.
- `tags`:  The user specified key and value pair tags being added to a Data Store.

"""
function tag_resource(ResourceARN, Tags; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(SERVICE_PARAMETER_MAP, kwargs)
    return healthlake("TagResource", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ResourceARN"=>ResourceARN, "Tags"=>Tags), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    untag_resource(resource_arn, tag_keys; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

 Removes tags from a Data Store.

# Arguments
- `resource_arn`:  \"The Amazon Resource Name(ARN) of the Data Store for which tags are
  being removed
- `tag_keys`:  The keys for the tags to be removed from the Healthlake Data Store.

"""
function untag_resource(ResourceARN, TagKeys; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(SERVICE_PARAMETER_MAP, kwargs)
    return healthlake("UntagResource", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ResourceARN"=>ResourceARN, "TagKeys"=>TagKeys), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end
