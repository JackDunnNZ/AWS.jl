# This file is auto-generated by AWSMetadata.jl
using AWS
using AWS.AWSServices: glue
using AWS.Compat
using AWS.UUIDs

# Julia syntax for service-level optional parameters to the AWS request syntax
const SERVICE_PARAMETER_MAP = OrderedCollections.LittleDict("location" => "Location", "sinks" => "Sinks", "catalog_id" => "CatalogId", "max_results" => "MaxResults", "next_token" => "NextToken", "expression" => "Expression", "csv_classifier" => "CsvClassifier", "grok_classifier" => "GrokClassifier", "json_classifier" => "JsonClassifier", "xmlclassifier" => "XMLClassifier", "partition_indexes" => "PartitionIndexes", "filter" => "Filter", "sort" => "Sort", "metadata_list" => "MetadataList", "schema_id" => "SchemaId", "schema_version_id" => "SchemaVersionId", "schema_version_number" => "SchemaVersionNumber", "compatibility" => "Compatibility", "description" => "Description", "filters" => "Filters", "resource_share_type" => "ResourceShareType", "search_text" => "SearchText", "sort_criteria" => "SortCriteria", "include_blueprint" => "IncludeBlueprint", "include_parameter_spec" => "IncludeParameterSpec", "registry_id" => "RegistryId", "crawler_name_list" => "CrawlerNameList", "classifiers" => "Classifiers", "configuration" => "Configuration", "crawler_security_configuration" => "CrawlerSecurityConfiguration", "database_name" => "DatabaseName", "lineage_configuration" => "LineageConfiguration", "recrawl_policy" => "RecrawlPolicy", "role" => "Role", "schedule" => "Schedule", "schema_change_policy" => "SchemaChangePolicy", "table_prefix" => "TablePrefix", "targets" => "Targets", "include_graph" => "IncludeGraph", "tags" => "Tags", "additional_plan_options_map" => "AdditionalPlanOptionsMap", "language" => "Language", "arguments" => "Arguments", "extra_jars_s3_path" => "ExtraJarsS3Path", "extra_python_libs_s3_path" => "ExtraPythonLibsS3Path", "glue_version" => "GlueVersion", "number_of_nodes" => "NumberOfNodes", "number_of_workers" => "NumberOfWorkers", "public_key" => "PublicKey", "public_keys" => "PublicKeys", "security_configuration" => "SecurityConfiguration", "security_group_ids" => "SecurityGroupIds", "subnet_id" => "SubnetId", "worker_type" => "WorkerType", "python_script" => "PythonScript", "schema_definition" => "SchemaDefinition", "dag_edges" => "DagEdges", "dag_nodes" => "DagNodes", "hide_password" => "HidePassword", "allocated_capacity" => "AllocatedCapacity", "job_run_id" => "JobRunId", "max_capacity" => "MaxCapacity", "notification_property" => "NotificationProperty", "timeout" => "Timeout", "resource_arn" => "ResourceArn", "enable_hybrid" => "EnableHybrid", "policy_exists_condition" => "PolicyExistsCondition", "policy_hash_condition" => "PolicyHashCondition", "add_arguments" => "AddArguments", "add_public_keys" => "AddPublicKeys", "custom_libraries" => "CustomLibraries", "delete_arguments" => "DeleteArguments", "delete_public_keys" => "DeletePublicKeys", "update_etl_libraries" => "UpdateEtlLibraries", "skip_archive" => "SkipArchive", "connections" => "Connections", "default_arguments" => "DefaultArguments", "execution_property" => "ExecutionProperty", "log_uri" => "LogUri", "max_retries" => "MaxRetries", "non_overridable_arguments" => "NonOverridableArguments", "parameters" => "Parameters", "predecessors_included" => "PredecessorsIncluded", "default_run_properties" => "DefaultRunProperties", "max_concurrent_runs" => "MaxConcurrentRuns", "version_id" => "VersionId", "event_batching_condition" => "EventBatchingCondition", "predicate" => "Predicate", "start_on_creation" => "StartOnCreation", "workflow_name" => "WorkflowName", "exclude_column_schema" => "ExcludeColumnSchema", "segment" => "Segment", "name" => "Name", "transform_encryption" => "TransformEncryption", "replace_all_labels" => "ReplaceAllLabels", "run_id" => "RunId", "dependent_job_name" => "DependentJobName")

"""
    batch_create_partition(database_name, partition_input_list, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates one or more partitions in a batch operation.

# Arguments
- `database_name`: The name of the metadata database in which the partition is to be
  created.
- `partition_input_list`: A list of PartitionInput structures that define the partitions to
  be created.
- `table_name`: The name of the metadata table in which the partition is to be created.

# Keyword Parameters
- `catalog_id`: The ID of the catalog in which the partition is to be created. Currently,
  this should be the Amazon Web Services account ID.
"""
function batch_create_partition(DatabaseName, PartitionInputList, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchCreatePartition", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "PartitionInputList"=>PartitionInputList, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    batch_delete_connection(connection_name_list; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes a list of connection definitions from the Data Catalog.

# Arguments
- `connection_name_list`: A list of names of the connections to delete.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog in which the connections reside. If none is
  provided, the Amazon Web Services account ID is used by default.
"""
function batch_delete_connection(ConnectionNameList; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchDeleteConnection", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ConnectionNameList"=>ConnectionNameList), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    batch_delete_partition(database_name, partitions_to_delete, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes one or more partitions in a batch operation.

# Arguments
- `database_name`: The name of the catalog database in which the table in question resides.
- `partitions_to_delete`: A list of PartitionInput structures that define the partitions to
  be deleted.
- `table_name`: The name of the table that contains the partitions to be deleted.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the partition to be deleted resides. If
  none is provided, the Amazon Web Services account ID is used by default.
"""
function batch_delete_partition(DatabaseName, PartitionsToDelete, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchDeletePartition", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "PartitionsToDelete"=>PartitionsToDelete, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    batch_delete_table(database_name, tables_to_delete; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes multiple tables at once.  After completing this operation, you no longer have
access to the table versions and partitions that belong to the deleted table. Glue deletes
these \"orphaned\" resources asynchronously in a timely manner, at the discretion of the
service. To ensure the immediate deletion of all related resources, before calling
BatchDeleteTable, use DeleteTableVersion or BatchDeleteTableVersion, and DeletePartition or
BatchDeletePartition, to delete any resources that belong to the table.

# Arguments
- `database_name`: The name of the catalog database in which the tables to delete reside.
  For Hive compatibility, this name is entirely lowercase.
- `tables_to_delete`: A list of the table to delete.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the table resides. If none is provided,
  the Amazon Web Services account ID is used by default.
"""
function batch_delete_table(DatabaseName, TablesToDelete; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchDeleteTable", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "TablesToDelete"=>TablesToDelete), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    batch_delete_table_version(database_name, table_name, version_ids; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes a specified batch of versions of a table.

# Arguments
- `database_name`: The database in the catalog in which the table resides. For Hive
  compatibility, this name is entirely lowercase.
- `table_name`: The name of the table. For Hive compatibility, this name is entirely
  lowercase.
- `version_ids`: A list of the IDs of versions to be deleted. A VersionId is a string
  representation of an integer. Each version is incremented by 1.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the tables reside. If none is provided,
  the Amazon Web Services account ID is used by default.
"""
function batch_delete_table_version(DatabaseName, TableName, VersionIds; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchDeleteTableVersion", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "TableName"=>TableName, "VersionIds"=>VersionIds), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    batch_get_blueprints(names; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves information about a list of blueprints.

# Arguments
- `names`: A list of blueprint names.

# Keyword Parameters
- `include_blueprint`: Specifies whether or not to include the blueprint in the response.
- `include_parameter_spec`: Specifies whether or not to include the parameters, as a JSON
  string, for the blueprint in the response.
"""
function batch_get_blueprints(Names; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchGetBlueprints", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Names"=>Names), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    batch_get_crawlers(crawler_names; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Returns a list of resource metadata for a given list of crawler names. After calling the
ListCrawlers operation, you can call this operation to access the data to which you have
been granted permissions. This operation supports all IAM permissions, including permission
conditions that uses tags.

# Arguments
- `crawler_names`: A list of crawler names, which might be the names returned from the
  ListCrawlers operation.

"""
function batch_get_crawlers(CrawlerNames; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchGetCrawlers", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("CrawlerNames"=>CrawlerNames), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    batch_get_dev_endpoints(dev_endpoint_names; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Returns a list of resource metadata for a given list of development endpoint names. After
calling the ListDevEndpoints operation, you can call this operation to access the data to
which you have been granted permissions. This operation supports all IAM permissions,
including permission conditions that uses tags.

# Arguments
- `dev_endpoint_names`: The list of DevEndpoint names, which might be the names returned
  from the ListDevEndpoint operation.

"""
function batch_get_dev_endpoints(DevEndpointNames; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchGetDevEndpoints", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DevEndpointNames"=>DevEndpointNames), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    batch_get_jobs(job_names; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Returns a list of resource metadata for a given list of job names. After calling the
ListJobs operation, you can call this operation to access the data to which you have been
granted permissions. This operation supports all IAM permissions, including permission
conditions that uses tags.

# Arguments
- `job_names`: A list of job names, which might be the names returned from the ListJobs
  operation.

"""
function batch_get_jobs(JobNames; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchGetJobs", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("JobNames"=>JobNames), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    batch_get_partition(database_name, partitions_to_get, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves partitions in a batch request.

# Arguments
- `database_name`: The name of the catalog database where the partitions reside.
- `partitions_to_get`: A list of partition values identifying the partitions to retrieve.
- `table_name`: The name of the partitions' table.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the partitions in question reside. If none
  is supplied, the Amazon Web Services account ID is used by default.
"""
function batch_get_partition(DatabaseName, PartitionsToGet, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchGetPartition", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "PartitionsToGet"=>PartitionsToGet, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    batch_get_triggers(trigger_names; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Returns a list of resource metadata for a given list of trigger names. After calling the
ListTriggers operation, you can call this operation to access the data to which you have
been granted permissions. This operation supports all IAM permissions, including permission
conditions that uses tags.

# Arguments
- `trigger_names`: A list of trigger names, which may be the names returned from the
  ListTriggers operation.

"""
function batch_get_triggers(TriggerNames; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchGetTriggers", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("TriggerNames"=>TriggerNames), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    batch_get_workflows(names; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Returns a list of resource metadata for a given list of workflow names. After calling the
ListWorkflows operation, you can call this operation to access the data to which you have
been granted permissions. This operation supports all IAM permissions, including permission
conditions that uses tags.

# Arguments
- `names`: A list of workflow names, which may be the names returned from the ListWorkflows
  operation.

# Keyword Parameters
- `include_graph`: Specifies whether to include a graph when returning the workflow
  resource metadata.
"""
function batch_get_workflows(Names; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchGetWorkflows", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Names"=>Names), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    batch_stop_job_run(job_name, job_run_ids; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Stops one or more job runs for a specified job definition.

# Arguments
- `job_name`: The name of the job definition for which to stop job runs.
- `job_run_ids`: A list of the JobRunIds that should be stopped for that job definition.

"""
function batch_stop_job_run(JobName, JobRunIds; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchStopJobRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("JobName"=>JobName, "JobRunIds"=>JobRunIds), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    batch_update_partition(database_name, entries, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates one or more partitions in a batch operation.

# Arguments
- `database_name`: The name of the metadata database in which the partition is to be
  updated.
- `entries`: A list of up to 100 BatchUpdatePartitionRequestEntry objects to update.
- `table_name`: The name of the metadata table in which the partition is to be updated.

# Keyword Parameters
- `catalog_id`: The ID of the catalog in which the partition is to be updated. Currently,
  this should be the Amazon Web Services account ID.
"""
function batch_update_partition(DatabaseName, Entries, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("BatchUpdatePartition", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "Entries"=>Entries, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    cancel_mltask_run(task_run_id, transform_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Cancels (stops) a task run. Machine learning task runs are asynchronous tasks that Glue
runs on your behalf as part of various machine learning workflows. You can cancel a machine
learning task run at any time by calling CancelMLTaskRun with a task run's parent
transform's TransformID and the task run's TaskRunId.

# Arguments
- `task_run_id`: A unique identifier for the task run.
- `transform_id`: The unique identifier of the machine learning transform.

"""
function cancel_mltask_run(TaskRunId, TransformId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CancelMLTaskRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("TaskRunId"=>TaskRunId, "TransformId"=>TransformId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    check_schema_version_validity(data_format, schema_definition; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Validates the supplied schema. This call has no side effects, it simply validates using the
supplied schema using DataFormat as the format. Since it does not take a schema set name,
no compatibility checks are performed.

# Arguments
- `data_format`: The data format of the schema definition. Currently AVRO and JSON are
  supported.
- `schema_definition`: The definition of the schema that has to be validated.

"""
function check_schema_version_validity(DataFormat, SchemaDefinition; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CheckSchemaVersionValidity", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DataFormat"=>DataFormat, "SchemaDefinition"=>SchemaDefinition), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_blueprint(blueprint_location, name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Registers a blueprint with Glue.

# Arguments
- `blueprint_location`: Specifies a path in Amazon S3 where the blueprint is published.
- `name`: The name of the blueprint.

# Keyword Parameters
- `description`: A description of the blueprint.
- `tags`: The tags to be applied to this blueprint.
"""
function create_blueprint(BlueprintLocation, Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateBlueprint", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("BlueprintLocation"=>BlueprintLocation, "Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_classifier(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a classifier in the user's account. This can be a GrokClassifier, an XMLClassifier,
a JsonClassifier, or a CsvClassifier, depending on which field of the request is present.

# Keyword Parameters
- `csv_classifier`: A CsvClassifier object specifying the classifier to create.
- `grok_classifier`: A GrokClassifier object specifying the classifier to create.
- `json_classifier`: A JsonClassifier object specifying the classifier to create.
- `xmlclassifier`: An XMLClassifier object specifying the classifier to create.
"""
function create_classifier(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateClassifier", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_connection(connection_input; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a connection definition in the Data Catalog.

# Arguments
- `connection_input`: A ConnectionInput object defining the connection to create.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog in which to create the connection. If none is
  provided, the Amazon Web Services account ID is used by default.
- `tags`: The tags you assign to the connection.
"""
function create_connection(ConnectionInput; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateConnection", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ConnectionInput"=>ConnectionInput), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_crawler(name, role, targets; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a new crawler with specified targets, role, configuration, and optional schedule.
At least one crawl target must be specified, in the s3Targets field, the jdbcTargets field,
or the DynamoDBTargets field.

# Arguments
- `name`: Name of the new crawler.
- `role`: The IAM role or Amazon Resource Name (ARN) of an IAM role used by the new crawler
  to access customer resources.
- `targets`: A list of collection of targets to crawl.

# Keyword Parameters
- `classifiers`: A list of custom classifiers that the user has registered. By default, all
  built-in classifiers are included in a crawl, but these custom classifiers always override
  the default classifiers for a given classification.
- `configuration`: Crawler configuration information. This versioned JSON string allows
  users to specify aspects of a crawler's behavior. For more information, see Configuring a
  Crawler.
- `crawler_security_configuration`: The name of the SecurityConfiguration structure to be
  used by this crawler.
- `database_name`: The Glue database where results are written, such as:
  arn:aws:daylight:us-east-1::database/sometable/*.
- `description`: A description of the new crawler.
- `lineage_configuration`: Specifies data lineage configuration settings for the crawler.
- `recrawl_policy`: A policy that specifies whether to crawl the entire dataset again, or
  to crawl only folders that were added since the last crawler run.
- `schedule`: A cron expression used to specify the schedule (see Time-Based Schedules for
  Jobs and Crawlers. For example, to run something every day at 12:15 UTC, you would specify:
  cron(15 12 * * ? *).
- `schema_change_policy`: The policy for the crawler's update and deletion behavior.
- `table_prefix`: The table prefix used for catalog tables that are created.
- `tags`: The tags to use with this crawler request. You may use tags to limit access to
  the crawler. For more information about tags in Glue, see Amazon Web Services Tags in Glue
  in the developer guide.
"""
function create_crawler(Name, Role, Targets; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateCrawler", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name, "Role"=>Role, "Targets"=>Targets), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_database(database_input; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a new database in a Data Catalog.

# Arguments
- `database_input`: The metadata for the database.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog in which to create the database. If none is
  provided, the Amazon Web Services account ID is used by default.
"""
function create_database(DatabaseInput; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateDatabase", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseInput"=>DatabaseInput), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_dev_endpoint(endpoint_name, role_arn; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a new development endpoint.

# Arguments
- `endpoint_name`: The name to be assigned to the new DevEndpoint.
- `role_arn`: The IAM role for the DevEndpoint.

# Keyword Parameters
- `arguments`: A map of arguments used to configure the DevEndpoint.
- `extra_jars_s3_path`: The path to one or more Java .jar files in an S3 bucket that should
  be loaded in your DevEndpoint.
- `extra_python_libs_s3_path`: The paths to one or more Python libraries in an Amazon S3
  bucket that should be loaded in your DevEndpoint. Multiple values must be complete paths
  separated by a comma.  You can only use pure Python libraries with a DevEndpoint. Libraries
  that rely on C extensions, such as the pandas Python data analysis library, are not yet
  supported.
- `glue_version`: Glue version determines the versions of Apache Spark and Python that Glue
  supports. The Python version indicates the version supported for running your ETL scripts
  on development endpoints.  For more information about the available Glue versions and
  corresponding Spark and Python versions, see Glue version in the developer guide.
  Development endpoints that are created without specifying a Glue version default to Glue
  0.9. You can specify a version of Python support for development endpoints by using the
  Arguments parameter in the CreateDevEndpoint or UpdateDevEndpoint APIs. If no arguments are
  provided, the version defaults to Python 2.
- `number_of_nodes`: The number of Glue Data Processing Units (DPUs) to allocate to this
  DevEndpoint.
- `number_of_workers`: The number of workers of a defined workerType that are allocated to
  the development endpoint. The maximum number of workers you can define are 299 for G.1X,
  and 149 for G.2X.
- `public_key`: The public key to be used by this DevEndpoint for authentication. This
  attribute is provided for backward compatibility because the recommended attribute to use
  is public keys.
- `public_keys`: A list of public keys to be used by the development endpoints for
  authentication. The use of this attribute is preferred over a single public key because the
  public keys allow you to have a different private key per client.  If you previously
  created an endpoint with a public key, you must remove that key to be able to set a list of
  public keys. Call the UpdateDevEndpoint API with the public key content in the
  deletePublicKeys attribute, and the list of new keys in the addPublicKeys attribute.
- `security_configuration`: The name of the SecurityConfiguration structure to be used with
  this DevEndpoint.
- `security_group_ids`: Security group IDs for the security groups to be used by the new
  DevEndpoint.
- `subnet_id`: The subnet ID for the new DevEndpoint to use.
- `tags`: The tags to use with this DevEndpoint. You may use tags to limit access to the
  DevEndpoint. For more information about tags in Glue, see Amazon Web Services Tags in Glue
  in the developer guide.
- `worker_type`: The type of predefined worker that is allocated to the development
  endpoint. Accepts a value of Standard, G.1X, or G.2X.   For the Standard worker type, each
  worker provides 4 vCPU, 16 GB of memory and a 50GB disk, and 2 executors per worker.   For
  the G.1X worker type, each worker maps to 1 DPU (4 vCPU, 16 GB of memory, 64 GB disk), and
  provides 1 executor per worker. We recommend this worker type for memory-intensive jobs.
  For the G.2X worker type, each worker maps to 2 DPU (8 vCPU, 32 GB of memory, 128 GB disk),
  and provides 1 executor per worker. We recommend this worker type for memory-intensive
  jobs.   Known issue: when a development endpoint is created with the G.2X WorkerType
  configuration, the Spark drivers for the development endpoint will run on 4 vCPU, 16 GB of
  memory, and a 64 GB disk.
"""
function create_dev_endpoint(EndpointName, RoleArn; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateDevEndpoint", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("EndpointName"=>EndpointName, "RoleArn"=>RoleArn), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_job(command, name, role; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a new job definition.

# Arguments
- `command`: The JobCommand that runs this job.
- `name`: The name you assign to this job definition. It must be unique in your account.
- `role`: The name or Amazon Resource Name (ARN) of the IAM role associated with this job.

# Keyword Parameters
- `allocated_capacity`: This parameter is deprecated. Use MaxCapacity instead. The number
  of Glue data processing units (DPUs) to allocate to this Job. You can allocate from 2 to
  100 DPUs; the default is 10. A DPU is a relative measure of processing power that consists
  of 4 vCPUs of compute capacity and 16 GB of memory. For more information, see the Glue
  pricing page.
- `connections`: The connections used for this job.
- `default_arguments`: The default arguments for this job. You can specify arguments here
  that your own job-execution script consumes, as well as arguments that Glue itself
  consumes. For information about how to specify and consume your own Job arguments, see the
  Calling Glue APIs in Python topic in the developer guide. For information about the
  key-value pairs that Glue consumes to set up your job, see the Special Parameters Used by
  Glue topic in the developer guide.
- `description`: Description of the job being defined.
- `execution_property`: An ExecutionProperty specifying the maximum number of concurrent
  runs allowed for this job.
- `glue_version`: Glue version determines the versions of Apache Spark and Python that Glue
  supports. The Python version indicates the version supported for jobs of type Spark.  For
  more information about the available Glue versions and corresponding Spark and Python
  versions, see Glue version in the developer guide. Jobs that are created without specifying
  a Glue version default to Glue 0.9.
- `log_uri`: This field is reserved for future use.
- `max_capacity`: For Glue version 1.0 or earlier jobs, using the standard worker type, the
  number of Glue data processing units (DPUs) that can be allocated when this job runs. A DPU
  is a relative measure of processing power that consists of 4 vCPUs of compute capacity and
  16 GB of memory. For more information, see the Glue pricing page. Do not set Max Capacity
  if using WorkerType and NumberOfWorkers. The value that can be allocated for MaxCapacity
  depends on whether you are running a Python shell job or an Apache Spark ETL job:   When
  you specify a Python shell job (JobCommand.Name=\"pythonshell\"), you can allocate either
  0.0625 or 1 DPU. The default is 0.0625 DPU.   When you specify an Apache Spark ETL job
  (JobCommand.Name=\"glueetl\") or Apache Spark streaming ETL job
  (JobCommand.Name=\"gluestreaming\"), you can allocate from 2 to 100 DPUs. The default is 10
  DPUs. This job type cannot have a fractional DPU allocation.   For Glue version 2.0 jobs,
  you cannot instead specify a Maximum capacity. Instead, you should specify a Worker type
  and the Number of workers.
- `max_retries`: The maximum number of times to retry this job if it fails.
- `non_overridable_arguments`: Non-overridable arguments for this job, specified as
  name-value pairs.
- `notification_property`: Specifies configuration properties of a job notification.
- `number_of_workers`: The number of workers of a defined workerType that are allocated
  when a job runs. The maximum number of workers you can define are 299 for G.1X, and 149 for
  G.2X.
- `security_configuration`: The name of the SecurityConfiguration structure to be used with
  this job.
- `tags`: The tags to use with this job. You may use tags to limit access to the job. For
  more information about tags in Glue, see Amazon Web Services Tags in Glue in the developer
  guide.
- `timeout`: The job timeout in minutes. This is the maximum time that a job run can
  consume resources before it is terminated and enters TIMEOUT status. The default is 2,880
  minutes (48 hours).
- `worker_type`: The type of predefined worker that is allocated when a job runs. Accepts a
  value of Standard, G.1X, or G.2X.   For the Standard worker type, each worker provides 4
  vCPU, 16 GB of memory and a 50GB disk, and 2 executors per worker.   For the G.1X worker
  type, each worker maps to 1 DPU (4 vCPU, 16 GB of memory, 64 GB disk), and provides 1
  executor per worker. We recommend this worker type for memory-intensive jobs.   For the
  G.2X worker type, each worker maps to 2 DPU (8 vCPU, 32 GB of memory, 128 GB disk), and
  provides 1 executor per worker. We recommend this worker type for memory-intensive jobs.
"""
function create_job(Command, Name, Role; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateJob", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Command"=>Command, "Name"=>Name, "Role"=>Role), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_mltransform(input_record_tables, name, parameters, role; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates an Glue machine learning transform. This operation creates the transform and all
the necessary parameters to train it. Call this operation as the first step in the process
of using a machine learning transform (such as the FindMatches transform) for deduplicating
data. You can provide an optional Description, in addition to the parameters that you want
to use for your algorithm. You must also specify certain parameters for the tasks that Glue
runs on your behalf as part of learning from your data and creating a high-quality machine
learning transform. These parameters include Role, and optionally, AllocatedCapacity,
Timeout, and MaxRetries. For more information, see Jobs.

# Arguments
- `input_record_tables`: A list of Glue table definitions used by the transform.
- `name`: The unique name that you give the transform when you create it.
- `parameters`: The algorithmic parameters that are specific to the transform type used.
  Conditionally dependent on the transform type.
- `role`: The name or Amazon Resource Name (ARN) of the IAM role with the required
  permissions. The required permissions include both Glue service role permissions to Glue
  resources, and Amazon S3 permissions required by the transform.    This role needs Glue
  service role permissions to allow access to resources in Glue. See Attach a Policy to IAM
  Users That Access Glue.   This role needs permission to your Amazon Simple Storage Service
  (Amazon S3) sources, targets, temporary directory, scripts, and any libraries used by the
  task run for this transform.

# Keyword Parameters
- `description`: A description of the machine learning transform that is being defined. The
  default is an empty string.
- `glue_version`: This value determines which version of Glue this machine learning
  transform is compatible with. Glue 1.0 is recommended for most customers. If the value is
  not set, the Glue compatibility defaults to Glue 0.9. For more information, see Glue
  Versions in the developer guide.
- `max_capacity`: The number of Glue data processing units (DPUs) that are allocated to
  task runs for this transform. You can allocate from 2 to 100 DPUs; the default is 10. A DPU
  is a relative measure of processing power that consists of 4 vCPUs of compute capacity and
  16 GB of memory. For more information, see the Glue pricing page.   MaxCapacity is a
  mutually exclusive option with NumberOfWorkers and WorkerType.   If either NumberOfWorkers
  or WorkerType is set, then MaxCapacity cannot be set.   If MaxCapacity is set then neither
  NumberOfWorkers or WorkerType can be set.   If WorkerType is set, then NumberOfWorkers is
  required (and vice versa).    MaxCapacity and NumberOfWorkers must both be at least 1.
  When the WorkerType field is set to a value other than Standard, the MaxCapacity field is
  set automatically and becomes read-only. When the WorkerType field is set to a value other
  than Standard, the MaxCapacity field is set automatically and becomes read-only.
- `max_retries`: The maximum number of times to retry a task for this transform after a
  task run fails.
- `number_of_workers`: The number of workers of a defined workerType that are allocated
  when this task runs. If WorkerType is set, then NumberOfWorkers is required (and vice
  versa).
- `tags`: The tags to use with this machine learning transform. You may use tags to limit
  access to the machine learning transform. For more information about tags in Glue, see
  Amazon Web Services Tags in Glue in the developer guide.
- `timeout`: The timeout of the task run for this transform in minutes. This is the maximum
  time that a task run for this transform can consume resources before it is terminated and
  enters TIMEOUT status. The default is 2,880 minutes (48 hours).
- `transform_encryption`: The encryption-at-rest settings of the transform that apply to
  accessing user data. Machine learning transforms can access user data encrypted in Amazon
  S3 using KMS.
- `worker_type`: The type of predefined worker that is allocated when this task runs.
  Accepts a value of Standard, G.1X, or G.2X.   For the Standard worker type, each worker
  provides 4 vCPU, 16 GB of memory and a 50GB disk, and 2 executors per worker.   For the
  G.1X worker type, each worker provides 4 vCPU, 16 GB of memory and a 64GB disk, and 1
  executor per worker.   For the G.2X worker type, each worker provides 8 vCPU, 32 GB of
  memory and a 128GB disk, and 1 executor per worker.    MaxCapacity is a mutually exclusive
  option with NumberOfWorkers and WorkerType.   If either NumberOfWorkers or WorkerType is
  set, then MaxCapacity cannot be set.   If MaxCapacity is set then neither NumberOfWorkers
  or WorkerType can be set.   If WorkerType is set, then NumberOfWorkers is required (and
  vice versa).    MaxCapacity and NumberOfWorkers must both be at least 1.
"""
function create_mltransform(InputRecordTables, Name, Parameters, Role; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateMLTransform", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("InputRecordTables"=>InputRecordTables, "Name"=>Name, "Parameters"=>Parameters, "Role"=>Role), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_partition(database_name, partition_input, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a new partition.

# Arguments
- `database_name`: The name of the metadata database in which the partition is to be
  created.
- `partition_input`: A PartitionInput structure defining the partition to be created.
- `table_name`: The name of the metadata table in which the partition is to be created.

# Keyword Parameters
- `catalog_id`: The Amazon Web Services account ID of the catalog in which the partition is
  to be created.
"""
function create_partition(DatabaseName, PartitionInput, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreatePartition", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "PartitionInput"=>PartitionInput, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_partition_index(database_name, partition_index, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a specified partition index in an existing table.

# Arguments
- `database_name`: Specifies the name of a database in which you want to create a partition
  index.
- `partition_index`: Specifies a PartitionIndex structure to create a partition index in an
  existing table.
- `table_name`: Specifies the name of a table in which you want to create a partition index.

# Keyword Parameters
- `catalog_id`: The catalog ID where the table resides.
"""
function create_partition_index(DatabaseName, PartitionIndex, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreatePartitionIndex", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "PartitionIndex"=>PartitionIndex, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_registry(registry_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a new registry which may be used to hold a collection of schemas.

# Arguments
- `registry_name`: Name of the registry to be created of max length of 255, and may only
  contain letters, numbers, hyphen, underscore, dollar sign, or hash mark. No whitespace.

# Keyword Parameters
- `description`: A description of the registry. If description is not provided, there will
  not be any default value for this.
- `tags`: Amazon Web Services tags that contain a key value pair and may be searched by
  console, command line, or API.
"""
function create_registry(RegistryName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateRegistry", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("RegistryName"=>RegistryName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_schema(data_format, schema_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a new schema set and registers the schema definition. Returns an error if the
schema set already exists without actually registering the version. When the schema set is
created, a version checkpoint will be set to the first version. Compatibility mode
\"DISABLED\" restricts any additional schema versions from being added after the first
schema version. For all other compatibility modes, validation of compatibility settings
will be applied only from the second version onwards when the RegisterSchemaVersion API is
used. When this API is called without a RegistryId, this will create an entry for a
\"default-registry\" in the registry database tables, if it is not already present.

# Arguments
- `data_format`: The data format of the schema definition. Currently AVRO and JSON are
  supported.
- `schema_name`: Name of the schema to be created of max length of 255, and may only
  contain letters, numbers, hyphen, underscore, dollar sign, or hash mark. No whitespace.

# Keyword Parameters
- `compatibility`: The compatibility mode of the schema. The possible values are:    NONE:
  No compatibility mode applies. You can use this choice in development scenarios or if you
  do not know the compatibility mode that you want to apply to schemas. Any new version added
  will be accepted without undergoing a compatibility check.    DISABLED: This compatibility
  choice prevents versioning for a particular schema. You can use this choice to prevent
  future versioning of a schema.    BACKWARD: This compatibility choice is recommended as it
  allows data receivers to read both the current and one previous schema version. This means
  that for instance, a new schema version cannot drop data fields or change the type of these
  fields, so they can't be read by readers using the previous version.    BACKWARD_ALL: This
  compatibility choice allows data receivers to read both the current and all previous schema
  versions. You can use this choice when you need to delete fields or add optional fields,
  and check compatibility against all previous schema versions.     FORWARD: This
  compatibility choice allows data receivers to read both the current and one next schema
  version, but not necessarily later versions. You can use this choice when you need to add
  fields or delete optional fields, but only check compatibility against the last schema
  version.    FORWARD_ALL: This compatibility choice allows data receivers to read written by
  producers of any new registered schema. You can use this choice when you need to add fields
  or delete optional fields, and check compatibility against all previous schema versions.
  FULL: This compatibility choice allows data receivers to read data written by producers
  using the previous or next version of the schema, but not necessarily earlier or later
  versions. You can use this choice when you need to add or remove optional fields, but only
  check compatibility against the last schema version.    FULL_ALL: This compatibility choice
  allows data receivers to read data written by producers using all previous schema versions.
  You can use this choice when you need to add or remove optional fields, and check
  compatibility against all previous schema versions.
- `description`: An optional description of the schema. If description is not provided,
  there will not be any automatic default value for this.
- `registry_id`:  This is a wrapper shape to contain the registry identity fields. If this
  is not provided, the default registry will be used. The ARN format for the same will be:
  arn:aws:glue:us-east-2:&lt;customer id&gt;:registry/default-registry:random-5-letter-id.
- `schema_definition`: The schema definition using the DataFormat setting for SchemaName.
- `tags`: Amazon Web Services tags that contain a key value pair and may be searched by
  console, command line, or API. If specified, follows the Amazon Web Services tags-on-create
  pattern.
"""
function create_schema(DataFormat, SchemaName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateSchema", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DataFormat"=>DataFormat, "SchemaName"=>SchemaName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_script(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Transforms a directed acyclic graph (DAG) into code.

# Keyword Parameters
- `dag_edges`: A list of the edges in the DAG.
- `dag_nodes`: A list of the nodes in the DAG.
- `language`: The programming language of the resulting code from the DAG.
"""
function create_script(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateScript", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_security_configuration(encryption_configuration, name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a new security configuration. A security configuration is a set of security
properties that can be used by Glue. You can use a security configuration to encrypt data
at rest. For information about using security configurations in Glue, see Encrypting Data
Written by Crawlers, Jobs, and Development Endpoints.

# Arguments
- `encryption_configuration`: The encryption configuration for the new security
  configuration.
- `name`: The name for the new security configuration.

"""
function create_security_configuration(EncryptionConfiguration, Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateSecurityConfiguration", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("EncryptionConfiguration"=>EncryptionConfiguration, "Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_table(database_name, table_input; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a new table definition in the Data Catalog.

# Arguments
- `database_name`: The catalog database in which to create the new table. For Hive
  compatibility, this name is entirely lowercase.
- `table_input`: The TableInput object that defines the metadata table to create in the
  catalog.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog in which to create the Table. If none is
  supplied, the Amazon Web Services account ID is used by default.
- `partition_indexes`: A list of partition indexes, PartitionIndex structures, to create in
  the table.
"""
function create_table(DatabaseName, TableInput; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateTable", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "TableInput"=>TableInput), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_trigger(actions, name, type; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a new trigger.

# Arguments
- `actions`: The actions initiated by this trigger when it fires.
- `name`: The name of the trigger.
- `type`: The type of the new trigger.

# Keyword Parameters
- `description`: A description of the new trigger.
- `event_batching_condition`: Batch condition that must be met (specified number of events
  received or batch time window expired) before EventBridge event trigger fires.
- `predicate`: A predicate to specify when the new trigger should fire. This field is
  required when the trigger type is CONDITIONAL.
- `schedule`: A cron expression used to specify the schedule (see Time-Based Schedules for
  Jobs and Crawlers. For example, to run something every day at 12:15 UTC, you would specify:
  cron(15 12 * * ? *). This field is required when the trigger type is SCHEDULED.
- `start_on_creation`: Set to true to start SCHEDULED and CONDITIONAL triggers when
  created. True is not supported for ON_DEMAND triggers.
- `tags`: The tags to use with this trigger. You may use tags to limit access to the
  trigger. For more information about tags in Glue, see Amazon Web Services Tags in Glue in
  the developer guide.
- `workflow_name`: The name of the workflow associated with the trigger.
"""
function create_trigger(Actions, Name, Type; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateTrigger", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Actions"=>Actions, "Name"=>Name, "Type"=>Type), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_user_defined_function(database_name, function_input; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a new function definition in the Data Catalog.

# Arguments
- `database_name`: The name of the catalog database in which to create the function.
- `function_input`: A FunctionInput object that defines the function to create in the Data
  Catalog.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog in which to create the function. If none is
  provided, the Amazon Web Services account ID is used by default.
"""
function create_user_defined_function(DatabaseName, FunctionInput; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateUserDefinedFunction", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "FunctionInput"=>FunctionInput), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    create_workflow(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates a new workflow.

# Arguments
- `name`: The name to be assigned to the workflow. It should be unique within your account.

# Keyword Parameters
- `default_run_properties`: A collection of properties to be used as part of each execution
  of the workflow.
- `description`: A description of the workflow.
- `max_concurrent_runs`: You can use this parameter to prevent unwanted multiple updates to
  data, to control costs, or in some cases, to prevent exceeding the maximum number of
  concurrent runs of any of the component jobs. If you leave this parameter blank, there is
  no limit to the number of concurrent workflow runs.
- `tags`: The tags to be used with this workflow.
"""
function create_workflow(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("CreateWorkflow", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_blueprint(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes an existing blueprint.

# Arguments
- `name`: The name of the blueprint to delete.

"""
function delete_blueprint(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteBlueprint", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_classifier(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Removes a classifier from the Data Catalog.

# Arguments
- `name`: Name of the classifier to remove.

"""
function delete_classifier(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteClassifier", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_column_statistics_for_partition(column_name, database_name, partition_values, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Delete the partition column statistics of a column. The Identity and Access Management
(IAM) permission required for this operation is DeletePartition.

# Arguments
- `column_name`: Name of the column.
- `database_name`: The name of the catalog database where the partitions reside.
- `partition_values`: A list of partition values identifying the partition.
- `table_name`: The name of the partitions' table.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the partitions in question reside. If none
  is supplied, the Amazon Web Services account ID is used by default.
"""
function delete_column_statistics_for_partition(ColumnName, DatabaseName, PartitionValues, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteColumnStatisticsForPartition", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ColumnName"=>ColumnName, "DatabaseName"=>DatabaseName, "PartitionValues"=>PartitionValues, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_column_statistics_for_table(column_name, database_name, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves table statistics of columns. The Identity and Access Management (IAM) permission
required for this operation is DeleteTable.

# Arguments
- `column_name`: The name of the column.
- `database_name`: The name of the catalog database where the partitions reside.
- `table_name`: The name of the partitions' table.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the partitions in question reside. If none
  is supplied, the Amazon Web Services account ID is used by default.
"""
function delete_column_statistics_for_table(ColumnName, DatabaseName, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteColumnStatisticsForTable", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ColumnName"=>ColumnName, "DatabaseName"=>DatabaseName, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_connection(connection_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes a connection from the Data Catalog.

# Arguments
- `connection_name`: The name of the connection to delete.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog in which the connection resides. If none is
  provided, the Amazon Web Services account ID is used by default.
"""
function delete_connection(ConnectionName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteConnection", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ConnectionName"=>ConnectionName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_crawler(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Removes a specified crawler from the Glue Data Catalog, unless the crawler state is RUNNING.

# Arguments
- `name`: The name of the crawler to remove.

"""
function delete_crawler(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteCrawler", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_database(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Removes a specified database from a Data Catalog.  After completing this operation, you no
longer have access to the tables (and all table versions and partitions that might belong
to the tables) and the user-defined functions in the deleted database. Glue deletes these
\"orphaned\" resources asynchronously in a timely manner, at the discretion of the service.
To ensure the immediate deletion of all related resources, before calling DeleteDatabase,
use DeleteTableVersion or BatchDeleteTableVersion, DeletePartition or BatchDeletePartition,
DeleteUserDefinedFunction, and DeleteTable or BatchDeleteTable, to delete any resources
that belong to the database.

# Arguments
- `name`: The name of the database to delete. For Hive compatibility, this must be all
  lowercase.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog in which the database resides. If none is
  provided, the Amazon Web Services account ID is used by default.
"""
function delete_database(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteDatabase", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_dev_endpoint(endpoint_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes a specified development endpoint.

# Arguments
- `endpoint_name`: The name of the DevEndpoint.

"""
function delete_dev_endpoint(EndpointName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteDevEndpoint", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("EndpointName"=>EndpointName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_job(job_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes a specified job definition. If the job definition is not found, no exception is
thrown.

# Arguments
- `job_name`: The name of the job definition to delete.

"""
function delete_job(JobName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteJob", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("JobName"=>JobName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_mltransform(transform_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes an Glue machine learning transform. Machine learning transforms are a special type
of transform that use machine learning to learn the details of the transformation to be
performed by learning from examples provided by humans. These transformations are then
saved by Glue. If you no longer need a transform, you can delete it by calling
DeleteMLTransforms. However, any Glue jobs that still reference the deleted transform will
no longer succeed.

# Arguments
- `transform_id`: The unique identifier of the transform to delete.

"""
function delete_mltransform(TransformId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteMLTransform", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("TransformId"=>TransformId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_partition(database_name, partition_values, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes a specified partition.

# Arguments
- `database_name`: The name of the catalog database in which the table in question resides.
- `partition_values`: The values that define the partition.
- `table_name`: The name of the table that contains the partition to be deleted.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the partition to be deleted resides. If
  none is provided, the Amazon Web Services account ID is used by default.
"""
function delete_partition(DatabaseName, PartitionValues, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeletePartition", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "PartitionValues"=>PartitionValues, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_partition_index(database_name, index_name, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes a specified partition index from an existing table.

# Arguments
- `database_name`: Specifies the name of a database from which you want to delete a
  partition index.
- `index_name`: The name of the partition index to be deleted.
- `table_name`: Specifies the name of a table from which you want to delete a partition
  index.

# Keyword Parameters
- `catalog_id`: The catalog ID where the table resides.
"""
function delete_partition_index(DatabaseName, IndexName, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeletePartitionIndex", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "IndexName"=>IndexName, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_registry(registry_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Delete the entire registry including schema and all of its versions. To get the status of
the delete operation, you can call the GetRegistry API after the asynchronous call.
Deleting a registry will deactivate all online operations for the registry such as the
UpdateRegistry, CreateSchema, UpdateSchema, and RegisterSchemaVersion APIs.

# Arguments
- `registry_id`: This is a wrapper structure that may contain the registry name and Amazon
  Resource Name (ARN).

"""
function delete_registry(RegistryId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteRegistry", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("RegistryId"=>RegistryId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_resource_policy(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes a specified policy.

# Keyword Parameters
- `policy_hash_condition`: The hash value returned when this policy was set.
- `resource_arn`: The ARN of the Glue resource for the resource policy to be deleted.
"""
function delete_resource_policy(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteResourcePolicy", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_schema(schema_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes the entire schema set, including the schema set and all of its versions. To get the
status of the delete operation, you can call GetSchema API after the asynchronous call.
Deleting a registry will deactivate all online operations for the schema, such as the
GetSchemaByDefinition, and RegisterSchemaVersion APIs.

# Arguments
- `schema_id`: This is a wrapper structure that may contain the schema name and Amazon
  Resource Name (ARN).

"""
function delete_schema(SchemaId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteSchema", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("SchemaId"=>SchemaId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_schema_versions(schema_id, versions; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Remove versions from the specified schema. A version number or range may be supplied. If
the compatibility mode forbids deleting of a version that is necessary, such as
BACKWARDS_FULL, an error is returned. Calling the GetSchemaVersions API after this call
will list the status of the deleted versions. When the range of version numbers contain
check pointed version, the API will return a 409 conflict and will not proceed with the
deletion. You have to remove the checkpoint first using the DeleteSchemaCheckpoint API
before using this API. You cannot use the DeleteSchemaVersions API to delete the first
schema version in the schema set. The first schema version can only be deleted by the
DeleteSchema API. This operation will also delete the attached SchemaVersionMetadata under
the schema versions. Hard deletes will be enforced on the database. If the compatibility
mode forbids deleting of a version that is necessary, such as BACKWARDS_FULL, an error is
returned.

# Arguments
- `schema_id`: This is a wrapper structure that may contain the schema name and Amazon
  Resource Name (ARN).
- `versions`: A version range may be supplied which may be of the format:   a single
  version number, 5   a range, 5-8 : deletes versions 5, 6, 7, 8

"""
function delete_schema_versions(SchemaId, Versions; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteSchemaVersions", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("SchemaId"=>SchemaId, "Versions"=>Versions), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_security_configuration(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes a specified security configuration.

# Arguments
- `name`: The name of the security configuration to delete.

"""
function delete_security_configuration(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteSecurityConfiguration", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_table(database_name, name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Removes a table definition from the Data Catalog.  After completing this operation, you no
longer have access to the table versions and partitions that belong to the deleted table.
Glue deletes these \"orphaned\" resources asynchronously in a timely manner, at the
discretion of the service. To ensure the immediate deletion of all related resources,
before calling DeleteTable, use DeleteTableVersion or BatchDeleteTableVersion, and
DeletePartition or BatchDeletePartition, to delete any resources that belong to the table.

# Arguments
- `database_name`: The name of the catalog database in which the table resides. For Hive
  compatibility, this name is entirely lowercase.
- `name`: The name of the table to be deleted. For Hive compatibility, this name is
  entirely lowercase.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the table resides. If none is provided,
  the Amazon Web Services account ID is used by default.
"""
function delete_table(DatabaseName, Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteTable", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_table_version(database_name, table_name, version_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes a specified version of a table.

# Arguments
- `database_name`: The database in the catalog in which the table resides. For Hive
  compatibility, this name is entirely lowercase.
- `table_name`: The name of the table. For Hive compatibility, this name is entirely
  lowercase.
- `version_id`: The ID of the table version to be deleted. A VersionID is a string
  representation of an integer. Each version is incremented by 1.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the tables reside. If none is provided,
  the Amazon Web Services account ID is used by default.
"""
function delete_table_version(DatabaseName, TableName, VersionId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteTableVersion", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "TableName"=>TableName, "VersionId"=>VersionId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_trigger(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes a specified trigger. If the trigger is not found, no exception is thrown.

# Arguments
- `name`: The name of the trigger to delete.

"""
function delete_trigger(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteTrigger", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_user_defined_function(database_name, function_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes an existing function definition from the Data Catalog.

# Arguments
- `database_name`: The name of the catalog database where the function is located.
- `function_name`: The name of the function definition to be deleted.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the function to be deleted is located. If
  none is supplied, the Amazon Web Services account ID is used by default.
"""
function delete_user_defined_function(DatabaseName, FunctionName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteUserDefinedFunction", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "FunctionName"=>FunctionName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    delete_workflow(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Deletes a workflow.

# Arguments
- `name`: Name of the workflow to be deleted.

"""
function delete_workflow(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("DeleteWorkflow", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_blueprint(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the details of a blueprint.

# Arguments
- `name`: The name of the blueprint.

# Keyword Parameters
- `include_blueprint`: Specifies whether or not to include the blueprint in the response.
- `include_parameter_spec`: Specifies whether or not to include the parameter specification.
"""
function get_blueprint(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetBlueprint", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_blueprint_run(blueprint_name, run_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the details of a blueprint run.

# Arguments
- `blueprint_name`: The name of the blueprint.
- `run_id`: The run ID for the blueprint run you want to retrieve.

"""
function get_blueprint_run(BlueprintName, RunId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetBlueprintRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("BlueprintName"=>BlueprintName, "RunId"=>RunId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_blueprint_runs(blueprint_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the details of blueprint runs for a specified blueprint.

# Arguments
- `blueprint_name`: The name of the blueprint.

# Keyword Parameters
- `max_results`: The maximum size of a list to return.
- `next_token`: A continuation token, if this is a continuation request.
"""
function get_blueprint_runs(BlueprintName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetBlueprintRuns", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("BlueprintName"=>BlueprintName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_catalog_import_status(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the status of a migration operation.

# Keyword Parameters
- `catalog_id`: The ID of the catalog to migrate. Currently, this should be the Amazon Web
  Services account ID.
"""
function get_catalog_import_status(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetCatalogImportStatus", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_classifier(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieve a classifier by name.

# Arguments
- `name`: Name of the classifier to retrieve.

"""
function get_classifier(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetClassifier", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_classifiers(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Lists all classifier objects in the Data Catalog.

# Keyword Parameters
- `max_results`: The size of the list to return (optional).
- `next_token`: An optional continuation token.
"""
function get_classifiers(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetClassifiers", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_column_statistics_for_partition(column_names, database_name, partition_values, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves partition statistics of columns. The Identity and Access Management (IAM)
permission required for this operation is GetPartition.

# Arguments
- `column_names`: A list of the column names.
- `database_name`: The name of the catalog database where the partitions reside.
- `partition_values`: A list of partition values identifying the partition.
- `table_name`: The name of the partitions' table.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the partitions in question reside. If none
  is supplied, the Amazon Web Services account ID is used by default.
"""
function get_column_statistics_for_partition(ColumnNames, DatabaseName, PartitionValues, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetColumnStatisticsForPartition", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ColumnNames"=>ColumnNames, "DatabaseName"=>DatabaseName, "PartitionValues"=>PartitionValues, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_column_statistics_for_table(column_names, database_name, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves table statistics of columns. The Identity and Access Management (IAM) permission
required for this operation is GetTable.

# Arguments
- `column_names`: A list of the column names.
- `database_name`: The name of the catalog database where the partitions reside.
- `table_name`: The name of the partitions' table.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the partitions in question reside. If none
  is supplied, the Amazon Web Services account ID is used by default.
"""
function get_column_statistics_for_table(ColumnNames, DatabaseName, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetColumnStatisticsForTable", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ColumnNames"=>ColumnNames, "DatabaseName"=>DatabaseName, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_connection(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves a connection definition from the Data Catalog.

# Arguments
- `name`: The name of the connection definition to retrieve.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog in which the connection resides. If none is
  provided, the Amazon Web Services account ID is used by default.
- `hide_password`: Allows you to retrieve the connection metadata without returning the
  password. For instance, the AWS Glue console uses this flag to retrieve the connection, and
  does not display the password. Set this parameter when the caller might not have permission
  to use the KMS key to decrypt the password, but it does have permission to access the rest
  of the connection properties.
"""
function get_connection(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetConnection", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_connections(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves a list of connection definitions from the Data Catalog.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog in which the connections reside. If none is
  provided, the Amazon Web Services account ID is used by default.
- `filter`: A filter that controls which connections are returned.
- `hide_password`: Allows you to retrieve the connection metadata without returning the
  password. For instance, the AWS Glue console uses this flag to retrieve the connection, and
  does not display the password. Set this parameter when the caller might not have permission
  to use the KMS key to decrypt the password, but it does have permission to access the rest
  of the connection properties.
- `max_results`: The maximum number of connections to return in one response.
- `next_token`: A continuation token, if this is a continuation call.
"""
function get_connections(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetConnections", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_crawler(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves metadata for a specified crawler.

# Arguments
- `name`: The name of the crawler to retrieve metadata for.

"""
function get_crawler(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetCrawler", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_crawler_metrics(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves metrics about specified crawlers.

# Keyword Parameters
- `crawler_name_list`: A list of the names of crawlers about which to retrieve metrics.
- `max_results`: The maximum size of a list to return.
- `next_token`: A continuation token, if this is a continuation call.
"""
function get_crawler_metrics(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetCrawlerMetrics", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_crawlers(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves metadata for all crawlers defined in the customer account.

# Keyword Parameters
- `max_results`: The number of crawlers to return on each call.
- `next_token`: A continuation token, if this is a continuation request.
"""
function get_crawlers(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetCrawlers", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_data_catalog_encryption_settings(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the security configuration for a specified catalog.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog to retrieve the security configuration for. If
  none is provided, the Amazon Web Services account ID is used by default.
"""
function get_data_catalog_encryption_settings(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetDataCatalogEncryptionSettings", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_database(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the definition of a specified database.

# Arguments
- `name`: The name of the database to retrieve. For Hive compatibility, this should be all
  lowercase.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog in which the database resides. If none is
  provided, the Amazon Web Services account ID is used by default.
"""
function get_database(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetDatabase", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_databases(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves all databases defined in a given Data Catalog.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog from which to retrieve Databases. If none is
  provided, the Amazon Web Services account ID is used by default.
- `max_results`: The maximum number of databases to return in one response.
- `next_token`: A continuation token, if this is a continuation call.
- `resource_share_type`: Allows you to specify that you want to list the databases shared
  with your account. The allowable values are FOREIGN or ALL.    If set to FOREIGN, will list
  the databases shared with your account.    If set to ALL, will list the databases shared
  with your account, as well as the databases in yor local account.
"""
function get_databases(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetDatabases", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_dataflow_graph(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Transforms a Python script into a directed acyclic graph (DAG).

# Keyword Parameters
- `python_script`: The Python script to transform.
"""
function get_dataflow_graph(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetDataflowGraph", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_dev_endpoint(endpoint_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves information about a specified development endpoint.  When you create a
development endpoint in a virtual private cloud (VPC), Glue returns only a private IP
address, and the public IP address field is not populated. When you create a non-VPC
development endpoint, Glue returns only a public IP address.

# Arguments
- `endpoint_name`: Name of the DevEndpoint to retrieve information for.

"""
function get_dev_endpoint(EndpointName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetDevEndpoint", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("EndpointName"=>EndpointName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_dev_endpoints(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves all the development endpoints in this AWS account.  When you create a development
endpoint in a virtual private cloud (VPC), Glue returns only a private IP address and the
public IP address field is not populated. When you create a non-VPC development endpoint,
Glue returns only a public IP address.

# Keyword Parameters
- `max_results`: The maximum size of information to return.
- `next_token`: A continuation token, if this is a continuation call.
"""
function get_dev_endpoints(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetDevEndpoints", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_job(job_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves an existing job definition.

# Arguments
- `job_name`: The name of the job definition to retrieve.

"""
function get_job(JobName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetJob", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("JobName"=>JobName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_job_bookmark(job_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Returns information on a job bookmark entry.

# Arguments
- `job_name`: The name of the job in question.

# Keyword Parameters
- `run_id`: The unique run identifier associated with this job run.
"""
function get_job_bookmark(JobName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetJobBookmark", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("JobName"=>JobName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_job_run(job_name, run_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the metadata for a given job run.

# Arguments
- `job_name`: Name of the job definition being run.
- `run_id`: The ID of the job run.

# Keyword Parameters
- `predecessors_included`: True if a list of predecessor runs should be returned.
"""
function get_job_run(JobName, RunId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetJobRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("JobName"=>JobName, "RunId"=>RunId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_job_runs(job_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves metadata for all runs of a given job definition.

# Arguments
- `job_name`: The name of the job definition for which to retrieve all job runs.

# Keyword Parameters
- `max_results`: The maximum size of the response.
- `next_token`: A continuation token, if this is a continuation call.
"""
function get_job_runs(JobName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetJobRuns", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("JobName"=>JobName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_jobs(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves all current job definitions.

# Keyword Parameters
- `max_results`: The maximum size of the response.
- `next_token`: A continuation token, if this is a continuation call.
"""
function get_jobs(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetJobs", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_mapping(source; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates mappings.

# Arguments
- `source`: Specifies the source table.

# Keyword Parameters
- `location`: Parameters for the mapping.
- `sinks`: A list of target tables.
"""
function get_mapping(Source; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetMapping", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Source"=>Source), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_mltask_run(task_run_id, transform_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Gets details for a specific task run on a machine learning transform. Machine learning task
runs are asynchronous tasks that Glue runs on your behalf as part of various machine
learning workflows. You can check the stats of any task run by calling GetMLTaskRun with
the TaskRunID and its parent transform's TransformID.

# Arguments
- `task_run_id`: The unique identifier of the task run.
- `transform_id`: The unique identifier of the machine learning transform.

"""
function get_mltask_run(TaskRunId, TransformId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetMLTaskRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("TaskRunId"=>TaskRunId, "TransformId"=>TransformId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_mltask_runs(transform_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Gets a list of runs for a machine learning transform. Machine learning task runs are
asynchronous tasks that Glue runs on your behalf as part of various machine learning
workflows. You can get a sortable, filterable list of machine learning task runs by calling
GetMLTaskRuns with their parent transform's TransformID and other optional parameters as
documented in this section. This operation returns a list of historic runs and must be
paginated.

# Arguments
- `transform_id`: The unique identifier of the machine learning transform.

# Keyword Parameters
- `filter`: The filter criteria, in the TaskRunFilterCriteria structure, for the task run.
- `max_results`: The maximum number of results to return.
- `next_token`: A token for pagination of the results. The default is empty.
- `sort`: The sorting criteria, in the TaskRunSortCriteria structure, for the task run.
"""
function get_mltask_runs(TransformId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetMLTaskRuns", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("TransformId"=>TransformId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_mltransform(transform_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Gets an Glue machine learning transform artifact and all its corresponding metadata.
Machine learning transforms are a special type of transform that use machine learning to
learn the details of the transformation to be performed by learning from examples provided
by humans. These transformations are then saved by Glue. You can retrieve their metadata by
calling GetMLTransform.

# Arguments
- `transform_id`: The unique identifier of the transform, generated at the time that the
  transform was created.

"""
function get_mltransform(TransformId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetMLTransform", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("TransformId"=>TransformId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_mltransforms(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Gets a sortable, filterable list of existing Glue machine learning transforms. Machine
learning transforms are a special type of transform that use machine learning to learn the
details of the transformation to be performed by learning from examples provided by humans.
These transformations are then saved by Glue, and you can retrieve their metadata by
calling GetMLTransforms.

# Keyword Parameters
- `filter`: The filter transformation criteria.
- `max_results`: The maximum number of results to return.
- `next_token`: A paginated token to offset the results.
- `sort`: The sorting criteria.
"""
function get_mltransforms(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetMLTransforms", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_partition(database_name, partition_values, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves information about a specified partition.

# Arguments
- `database_name`: The name of the catalog database where the partition resides.
- `partition_values`: The values that define the partition.
- `table_name`: The name of the partition's table.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the partition in question resides. If none
  is provided, the Amazon Web Services account ID is used by default.
"""
function get_partition(DatabaseName, PartitionValues, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetPartition", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "PartitionValues"=>PartitionValues, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_partition_indexes(database_name, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the partition indexes associated with a table.

# Arguments
- `database_name`: Specifies the name of a database from which you want to retrieve
  partition indexes.
- `table_name`: Specifies the name of a table for which you want to retrieve the partition
  indexes.

# Keyword Parameters
- `catalog_id`: The catalog ID where the table resides.
- `next_token`: A continuation token, included if this is a continuation call.
"""
function get_partition_indexes(DatabaseName, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetPartitionIndexes", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_partitions(database_name, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves information about the partitions in a table.

# Arguments
- `database_name`: The name of the catalog database where the partitions reside.
- `table_name`: The name of the partitions' table.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the partitions in question reside. If none
  is provided, the Amazon Web Services account ID is used by default.
- `exclude_column_schema`: When true, specifies not returning the partition column schema.
  Useful when you are interested only in other partition attributes such as partition values
  or location. This approach avoids the problem of a large response by not returning
  duplicate data.
- `expression`: An expression that filters the partitions to be returned. The expression
  uses SQL syntax similar to the SQL WHERE filter clause. The SQL statement parser JSQLParser
  parses the expression.   Operators: The following are the operators that you can use in the
  Expression API call:  =  Checks whether the values of the two operands are equal; if yes,
  then the condition becomes true. Example: Assume 'variable a' holds 10 and 'variable b'
  holds 20.  (a = b) is not true.  &lt; &gt;  Checks whether the values of two operands are
  equal; if the values are not equal, then the condition becomes true. Example: (a &lt; &gt;
  b) is true.  &gt;  Checks whether the value of the left operand is greater than the value
  of the right operand; if yes, then the condition becomes true. Example: (a &gt; b) is not
  true.  &lt;  Checks whether the value of the left operand is less than the value of the
  right operand; if yes, then the condition becomes true. Example: (a &lt; b) is true.  &gt;=
   Checks whether the value of the left operand is greater than or equal to the value of the
  right operand; if yes, then the condition becomes true. Example: (a &gt;= b) is not true.
  &lt;=  Checks whether the value of the left operand is less than or equal to the value of
  the right operand; if yes, then the condition becomes true. Example: (a &lt;= b) is true.
  AND, OR, IN, BETWEEN, LIKE, NOT, IS NULL  Logical operators.    Supported Partition Key
  Types: The following are the supported partition keys.    string     date     timestamp
  int     bigint     long     tinyint     smallint     decimal    If an type is encountered
  that is not valid, an exception is thrown.  The following list shows the valid operators on
  each type. When you define a crawler, the partitionKey type is created as a STRING, to be
  compatible with the catalog partitions.   Sample API Call:
- `max_results`: The maximum number of partitions to return in a single response.
- `next_token`: A continuation token, if this is not the first call to retrieve these
  partitions.
- `segment`: The segment of the table's partitions to scan in this request.
"""
function get_partitions(DatabaseName, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetPartitions", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_plan(mapping, source; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Gets code to perform a specified mapping.

# Arguments
- `mapping`: The list of mappings from a source table to target tables.
- `source`: The source table.

# Keyword Parameters
- `additional_plan_options_map`: A map to hold additional optional key-value parameters.
  Currently, these key-value pairs are supported:    inferSchema  —  Specifies whether to
  set inferSchema to true or false for the default script generated by an Glue job. For
  example, to set inferSchema to true, pass the following key value pair:
  --additional-plan-options-map '{\"inferSchema\":\"true\"}'
- `language`: The programming language of the code to perform the mapping.
- `location`: The parameters for the mapping.
- `sinks`: The target tables.
"""
function get_plan(Mapping, Source; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetPlan", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Mapping"=>Mapping, "Source"=>Source), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_registry(registry_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Describes the specified registry in detail.

# Arguments
- `registry_id`: This is a wrapper structure that may contain the registry name and Amazon
  Resource Name (ARN).

"""
function get_registry(RegistryId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetRegistry", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("RegistryId"=>RegistryId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_resource_policies(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the resource policies set on individual resources by Resource Access Manager
during cross-account permission grants. Also retrieves the Data Catalog resource policy. If
you enabled metadata encryption in Data Catalog settings, and you do not have permission on
the KMS key, the operation can't return the Data Catalog resource policy.

# Keyword Parameters
- `max_results`: The maximum size of a list to return.
- `next_token`: A continuation token, if this is a continuation request.
"""
function get_resource_policies(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetResourcePolicies", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_resource_policy(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves a specified resource policy.

# Keyword Parameters
- `resource_arn`: The ARN of the Glue resource for which to retrieve the resource policy.
  If not supplied, the Data Catalog resource policy is returned. Use GetResourcePolicies to
  view all existing resource policies. For more information see Specifying Glue Resource
  ARNs.
"""
function get_resource_policy(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetResourcePolicy", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_schema(schema_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Describes the specified schema in detail.

# Arguments
- `schema_id`: This is a wrapper structure to contain schema identity fields. The structure
  contains:   SchemaIdSchemaArn: The Amazon Resource Name (ARN) of the schema. Either
  SchemaArn or SchemaName and RegistryName has to be provided.   SchemaIdSchemaName: The name
  of the schema. Either SchemaArn or SchemaName and RegistryName has to be provided.

"""
function get_schema(SchemaId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetSchema", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("SchemaId"=>SchemaId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_schema_by_definition(schema_definition, schema_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves a schema by the SchemaDefinition. The schema definition is sent to the Schema
Registry, canonicalized, and hashed. If the hash is matched within the scope of the
SchemaName or ARN (or the default registry, if none is supplied), that schema’s metadata
is returned. Otherwise, a 404 or NotFound error is returned. Schema versions in Deleted
statuses will not be included in the results.

# Arguments
- `schema_definition`: The definition of the schema for which schema details are required.
- `schema_id`: This is a wrapper structure to contain schema identity fields. The structure
  contains:   SchemaIdSchemaArn: The Amazon Resource Name (ARN) of the schema. One of
  SchemaArn or SchemaName has to be provided.   SchemaIdSchemaName: The name of the schema.
  One of SchemaArn or SchemaName has to be provided.

"""
function get_schema_by_definition(SchemaDefinition, SchemaId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetSchemaByDefinition", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("SchemaDefinition"=>SchemaDefinition, "SchemaId"=>SchemaId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_schema_version(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Get the specified schema by its unique ID assigned when a version of the schema is created
or registered. Schema versions in Deleted status will not be included in the results.

# Keyword Parameters
- `schema_id`: This is a wrapper structure to contain schema identity fields. The structure
  contains:   SchemaIdSchemaArn: The Amazon Resource Name (ARN) of the schema. Either
  SchemaArn or SchemaName and RegistryName has to be provided.   SchemaIdSchemaName: The name
  of the schema. Either SchemaArn or SchemaName and RegistryName has to be provided.
- `schema_version_id`: The SchemaVersionId of the schema version. This field is required
  for fetching by schema ID. Either this or the SchemaId wrapper has to be provided.
- `schema_version_number`: The version number of the schema.
"""
function get_schema_version(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetSchemaVersion", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_schema_versions_diff(first_schema_version_number, schema_diff_type, schema_id, second_schema_version_number; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Fetches the schema version difference in the specified difference type between two stored
schema versions in the Schema Registry. This API allows you to compare two schema versions
between two schema definitions under the same schema.

# Arguments
- `first_schema_version_number`: The first of the two schema versions to be compared.
- `schema_diff_type`: Refers to SYNTAX_DIFF, which is the currently supported diff type.
- `schema_id`: This is a wrapper structure to contain schema identity fields. The structure
  contains:   SchemaIdSchemaArn: The Amazon Resource Name (ARN) of the schema. One of
  SchemaArn or SchemaName has to be provided.   SchemaIdSchemaName: The name of the schema.
  One of SchemaArn or SchemaName has to be provided.
- `second_schema_version_number`: The second of the two schema versions to be compared.

"""
function get_schema_versions_diff(FirstSchemaVersionNumber, SchemaDiffType, SchemaId, SecondSchemaVersionNumber; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetSchemaVersionsDiff", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("FirstSchemaVersionNumber"=>FirstSchemaVersionNumber, "SchemaDiffType"=>SchemaDiffType, "SchemaId"=>SchemaId, "SecondSchemaVersionNumber"=>SecondSchemaVersionNumber), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_security_configuration(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves a specified security configuration.

# Arguments
- `name`: The name of the security configuration to retrieve.

"""
function get_security_configuration(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetSecurityConfiguration", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_security_configurations(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves a list of all security configurations.

# Keyword Parameters
- `max_results`: The maximum number of results to return.
- `next_token`: A continuation token, if this is a continuation call.
"""
function get_security_configurations(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetSecurityConfigurations", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_table(database_name, name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the Table definition in a Data Catalog for a specified table.

# Arguments
- `database_name`: The name of the database in the catalog in which the table resides. For
  Hive compatibility, this name is entirely lowercase.
- `name`: The name of the table for which to retrieve the definition. For Hive
  compatibility, this name is entirely lowercase.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the table resides. If none is provided,
  the Amazon Web Services account ID is used by default.
"""
function get_table(DatabaseName, Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetTable", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_table_version(database_name, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves a specified version of a table.

# Arguments
- `database_name`: The database in the catalog in which the table resides. For Hive
  compatibility, this name is entirely lowercase.
- `table_name`: The name of the table. For Hive compatibility, this name is entirely
  lowercase.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the tables reside. If none is provided,
  the Amazon Web Services account ID is used by default.
- `version_id`: The ID value of the table version to be retrieved. A VersionID is a string
  representation of an integer. Each version is incremented by 1.
"""
function get_table_version(DatabaseName, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetTableVersion", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_table_versions(database_name, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves a list of strings that identify available versions of a specified table.

# Arguments
- `database_name`: The database in the catalog in which the table resides. For Hive
  compatibility, this name is entirely lowercase.
- `table_name`: The name of the table. For Hive compatibility, this name is entirely
  lowercase.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the tables reside. If none is provided,
  the Amazon Web Services account ID is used by default.
- `max_results`: The maximum number of table versions to return in one response.
- `next_token`: A continuation token, if this is not the first call.
"""
function get_table_versions(DatabaseName, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetTableVersions", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_tables(database_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the definitions of some or all of the tables in a given Database.

# Arguments
- `database_name`: The database in the catalog whose tables to list. For Hive
  compatibility, this name is entirely lowercase.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the tables reside. If none is provided,
  the Amazon Web Services account ID is used by default.
- `expression`: A regular expression pattern. If present, only those tables whose names
  match the pattern are returned.
- `max_results`: The maximum number of tables to return in a single response.
- `next_token`: A continuation token, included if this is a continuation call.
"""
function get_tables(DatabaseName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetTables", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_tags(resource_arn; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves a list of tags associated with a resource.

# Arguments
- `resource_arn`: The Amazon Resource Name (ARN) of the resource for which to retrieve tags.

"""
function get_tags(ResourceArn; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetTags", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ResourceArn"=>ResourceArn), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_trigger(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the definition of a trigger.

# Arguments
- `name`: The name of the trigger to retrieve.

"""
function get_trigger(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetTrigger", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_triggers(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Gets all the triggers associated with a job.

# Keyword Parameters
- `dependent_job_name`: The name of the job to retrieve triggers for. The trigger that can
  start this job is returned, and if there is no such trigger, all triggers are returned.
- `max_results`: The maximum size of the response.
- `next_token`: A continuation token, if this is a continuation call.
"""
function get_triggers(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetTriggers", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_user_defined_function(database_name, function_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves a specified function definition from the Data Catalog.

# Arguments
- `database_name`: The name of the catalog database where the function is located.
- `function_name`: The name of the function.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the function to be retrieved is located.
  If none is provided, the Amazon Web Services account ID is used by default.
"""
function get_user_defined_function(DatabaseName, FunctionName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetUserDefinedFunction", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "FunctionName"=>FunctionName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_user_defined_functions(pattern; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves multiple function definitions from the Data Catalog.

# Arguments
- `pattern`: An optional function-name pattern string that filters the function definitions
  returned.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the functions to be retrieved are located.
  If none is provided, the Amazon Web Services account ID is used by default.
- `database_name`: The name of the catalog database where the functions are located. If
  none is provided, functions from all the databases across the catalog will be returned.
- `max_results`: The maximum number of functions to return in one response.
- `next_token`: A continuation token, if this is a continuation call.
"""
function get_user_defined_functions(Pattern; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetUserDefinedFunctions", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Pattern"=>Pattern), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_workflow(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves resource metadata for a workflow.

# Arguments
- `name`: The name of the workflow to retrieve.

# Keyword Parameters
- `include_graph`: Specifies whether to include a graph when returning the workflow
  resource metadata.
"""
function get_workflow(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetWorkflow", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_workflow_run(name, run_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the metadata for a given workflow run.

# Arguments
- `name`: Name of the workflow being run.
- `run_id`: The ID of the workflow run.

# Keyword Parameters
- `include_graph`: Specifies whether to include the workflow graph in response or not.
"""
function get_workflow_run(Name, RunId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetWorkflowRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name, "RunId"=>RunId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_workflow_run_properties(name, run_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the workflow run properties which were set during the run.

# Arguments
- `name`: Name of the workflow which was run.
- `run_id`: The ID of the workflow run whose run properties should be returned.

"""
function get_workflow_run_properties(Name, RunId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetWorkflowRunProperties", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name, "RunId"=>RunId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    get_workflow_runs(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves metadata for all runs of a given workflow.

# Arguments
- `name`: Name of the workflow whose metadata of runs should be returned.

# Keyword Parameters
- `include_graph`: Specifies whether to include the workflow graph in response or not.
- `max_results`: The maximum number of workflow runs to be included in the response.
- `next_token`: The maximum size of the response.
"""
function get_workflow_runs(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("GetWorkflowRuns", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    import_catalog_to_glue(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Imports an existing Amazon Athena Data Catalog to Glue.

# Keyword Parameters
- `catalog_id`: The ID of the catalog to import. Currently, this should be the Amazon Web
  Services account ID.
"""
function import_catalog_to_glue(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("ImportCatalogToGlue", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_blueprints(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Lists all the blueprint names in an account.

# Keyword Parameters
- `max_results`: The maximum size of a list to return.
- `next_token`: A continuation token, if this is a continuation request.
- `tags`: Filters the list by an Amazon Web Services resource tag.
"""
function list_blueprints(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("ListBlueprints", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_crawlers(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the names of all crawler resources in this Amazon Web Services account, or the
resources with the specified tag. This operation allows you to see which resources are
available in your account, and their names. This operation takes the optional Tags field,
which you can use as a filter on the response so that tagged resources can be retrieved as
a group. If you choose to use tags filtering, only resources with the tag are retrieved.

# Keyword Parameters
- `max_results`: The maximum size of a list to return.
- `next_token`: A continuation token, if this is a continuation request.
- `tags`: Specifies to return only these tagged resources.
"""
function list_crawlers(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("ListCrawlers", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_dev_endpoints(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the names of all DevEndpoint resources in this Amazon Web Services account, or
the resources with the specified tag. This operation allows you to see which resources are
available in your account, and their names. This operation takes the optional Tags field,
which you can use as a filter on the response so that tagged resources can be retrieved as
a group. If you choose to use tags filtering, only resources with the tag are retrieved.

# Keyword Parameters
- `max_results`: The maximum size of a list to return.
- `next_token`: A continuation token, if this is a continuation request.
- `tags`: Specifies to return only these tagged resources.
"""
function list_dev_endpoints(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("ListDevEndpoints", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_jobs(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the names of all job resources in this Amazon Web Services account, or the
resources with the specified tag. This operation allows you to see which resources are
available in your account, and their names. This operation takes the optional Tags field,
which you can use as a filter on the response so that tagged resources can be retrieved as
a group. If you choose to use tags filtering, only resources with the tag are retrieved.

# Keyword Parameters
- `max_results`: The maximum size of a list to return.
- `next_token`: A continuation token, if this is a continuation request.
- `tags`: Specifies to return only these tagged resources.
"""
function list_jobs(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("ListJobs", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_mltransforms(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

 Retrieves a sortable, filterable list of existing Glue machine learning transforms in this
Amazon Web Services account, or the resources with the specified tag. This operation takes
the optional Tags field, which you can use as a filter of the responses so that tagged
resources can be retrieved as a group. If you choose to use tag filtering, only resources
with the tags are retrieved.

# Keyword Parameters
- `filter`: A TransformFilterCriteria used to filter the machine learning transforms.
- `max_results`: The maximum size of a list to return.
- `next_token`: A continuation token, if this is a continuation request.
- `sort`: A TransformSortCriteria used to sort the machine learning transforms.
- `tags`: Specifies to return only these tagged resources.
"""
function list_mltransforms(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("ListMLTransforms", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_registries(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Returns a list of registries that you have created, with minimal registry information.
Registries in the Deleting status will not be included in the results. Empty results will
be returned if there are no registries available.

# Keyword Parameters
- `max_results`: Maximum number of results required per page. If the value is not supplied,
  this will be defaulted to 25 per page.
- `next_token`: A continuation token, if this is a continuation call.
"""
function list_registries(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("ListRegistries", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_schema_versions(schema_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Returns a list of schema versions that you have created, with minimal information. Schema
versions in Deleted status will not be included in the results. Empty results will be
returned if there are no schema versions available.

# Arguments
- `schema_id`: This is a wrapper structure to contain schema identity fields. The structure
  contains:   SchemaIdSchemaArn: The Amazon Resource Name (ARN) of the schema. Either
  SchemaArn or SchemaName and RegistryName has to be provided.   SchemaIdSchemaName: The name
  of the schema. Either SchemaArn or SchemaName and RegistryName has to be provided.

# Keyword Parameters
- `max_results`: Maximum number of results required per page. If the value is not supplied,
  this will be defaulted to 25 per page.
- `next_token`: A continuation token, if this is a continuation call.
"""
function list_schema_versions(SchemaId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("ListSchemaVersions", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("SchemaId"=>SchemaId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_schemas(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Returns a list of schemas with minimal details. Schemas in Deleting status will not be
included in the results. Empty results will be returned if there are no schemas available.
When the RegistryId is not provided, all the schemas across registries will be part of the
API response.

# Keyword Parameters
- `max_results`: Maximum number of results required per page. If the value is not supplied,
  this will be defaulted to 25 per page.
- `next_token`: A continuation token, if this is a continuation call.
- `registry_id`: A wrapper structure that may contain the registry name and Amazon Resource
  Name (ARN).
"""
function list_schemas(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("ListSchemas", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_triggers(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Retrieves the names of all trigger resources in this Amazon Web Services account, or the
resources with the specified tag. This operation allows you to see which resources are
available in your account, and their names. This operation takes the optional Tags field,
which you can use as a filter on the response so that tagged resources can be retrieved as
a group. If you choose to use tags filtering, only resources with the tag are retrieved.

# Keyword Parameters
- `dependent_job_name`:  The name of the job for which to retrieve triggers. The trigger
  that can start this job is returned. If there is no such trigger, all triggers are returned.
- `max_results`: The maximum size of a list to return.
- `next_token`: A continuation token, if this is a continuation request.
- `tags`: Specifies to return only these tagged resources.
"""
function list_triggers(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("ListTriggers", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    list_workflows(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Lists names of workflows created in the account.

# Keyword Parameters
- `max_results`: The maximum size of a list to return.
- `next_token`: A continuation token, if this is a continuation request.
"""
function list_workflows(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("ListWorkflows", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    put_data_catalog_encryption_settings(data_catalog_encryption_settings; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Sets the security configuration for a specified catalog. After the configuration has been
set, the specified encryption is applied to every catalog write thereafter.

# Arguments
- `data_catalog_encryption_settings`: The security configuration to set.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog to set the security configuration for. If none
  is provided, the Amazon Web Services account ID is used by default.
"""
function put_data_catalog_encryption_settings(DataCatalogEncryptionSettings; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("PutDataCatalogEncryptionSettings", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DataCatalogEncryptionSettings"=>DataCatalogEncryptionSettings), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    put_resource_policy(policy_in_json; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Sets the Data Catalog resource policy for access control.

# Arguments
- `policy_in_json`: Contains the policy document to set, in JSON format.

# Keyword Parameters
- `enable_hybrid`: If 'TRUE', indicates that you are using both methods to grant
  cross-account access to Data Catalog resources:   By directly updating the resource policy
  with PutResourePolicy    By using the Grant permissions command on the Amazon Web Services
  Management Console.   Must be set to 'TRUE' if you have already used the Management Console
  to grant cross-account access, otherwise the call fails. Default is 'FALSE'.
- `policy_exists_condition`: A value of MUST_EXIST is used to update a policy. A value of
  NOT_EXIST is used to create a new policy. If a value of NONE or a null value is used, the
  call does not depend on the existence of a policy.
- `policy_hash_condition`: The hash value returned when the previous policy was set using
  PutResourcePolicy. Its purpose is to prevent concurrent modifications of a policy. Do not
  use this parameter if no previous policy has been set.
- `resource_arn`: Do not use. For internal use only.
"""
function put_resource_policy(PolicyInJson; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("PutResourcePolicy", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("PolicyInJson"=>PolicyInJson), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    put_schema_version_metadata(metadata_key_value; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Puts the metadata key value pair for a specified schema version ID. A maximum of 10 key
value pairs will be allowed per schema version. They can be added over one or more calls.

# Arguments
- `metadata_key_value`: The metadata key's corresponding value.

# Keyword Parameters
- `schema_id`: The unique ID for the schema.
- `schema_version_id`: The unique version ID of the schema version.
- `schema_version_number`: The version number of the schema.
"""
function put_schema_version_metadata(MetadataKeyValue; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("PutSchemaVersionMetadata", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("MetadataKeyValue"=>MetadataKeyValue), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    put_workflow_run_properties(name, run_id, run_properties; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Puts the specified workflow run properties for the given workflow run. If a property
already exists for the specified run, then it overrides the value otherwise adds the
property to existing properties.

# Arguments
- `name`: Name of the workflow which was run.
- `run_id`: The ID of the workflow run for which the run properties should be updated.
- `run_properties`: The properties to put for the specified run.

"""
function put_workflow_run_properties(Name, RunId, RunProperties; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("PutWorkflowRunProperties", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name, "RunId"=>RunId, "RunProperties"=>RunProperties), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    query_schema_version_metadata(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Queries for the schema version metadata information.

# Keyword Parameters
- `max_results`: Maximum number of results required per page. If the value is not supplied,
  this will be defaulted to 25 per page.
- `metadata_list`: Search key-value pairs for metadata, if they are not provided all the
  metadata information will be fetched.
- `next_token`: A continuation token, if this is a continuation call.
- `schema_id`: A wrapper structure that may contain the schema name and Amazon Resource
  Name (ARN).
- `schema_version_id`: The unique version ID of the schema version.
- `schema_version_number`: The version number of the schema.
"""
function query_schema_version_metadata(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("QuerySchemaVersionMetadata", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    register_schema_version(schema_definition, schema_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Adds a new version to the existing schema. Returns an error if new version of schema does
not meet the compatibility requirements of the schema set. This API will not create a new
schema set and will return a 404 error if the schema set is not already present in the
Schema Registry. If this is the first schema definition to be registered in the Schema
Registry, this API will store the schema version and return immediately. Otherwise, this
call has the potential to run longer than other operations due to compatibility modes. You
can call the GetSchemaVersion API with the SchemaVersionId to check compatibility modes. If
the same schema definition is already stored in Schema Registry as a version, the schema ID
of the existing schema is returned to the caller.

# Arguments
- `schema_definition`: The schema definition using the DataFormat setting for the
  SchemaName.
- `schema_id`: This is a wrapper structure to contain schema identity fields. The structure
  contains:   SchemaIdSchemaArn: The Amazon Resource Name (ARN) of the schema. Either
  SchemaArn or SchemaName and RegistryName has to be provided.   SchemaIdSchemaName: The name
  of the schema. Either SchemaArn or SchemaName and RegistryName has to be provided.

"""
function register_schema_version(SchemaDefinition, SchemaId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("RegisterSchemaVersion", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("SchemaDefinition"=>SchemaDefinition, "SchemaId"=>SchemaId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    remove_schema_version_metadata(metadata_key_value; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Removes a key value pair from the schema version metadata for the specified schema version
ID.

# Arguments
- `metadata_key_value`: The value of the metadata key.

# Keyword Parameters
- `schema_id`: A wrapper structure that may contain the schema name and Amazon Resource
  Name (ARN).
- `schema_version_id`: The unique version ID of the schema version.
- `schema_version_number`: The version number of the schema.
"""
function remove_schema_version_metadata(MetadataKeyValue; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("RemoveSchemaVersionMetadata", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("MetadataKeyValue"=>MetadataKeyValue), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    reset_job_bookmark(job_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Resets a bookmark entry.

# Arguments
- `job_name`: The name of the job in question.

# Keyword Parameters
- `run_id`: The unique run identifier associated with this job run.
"""
function reset_job_bookmark(JobName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("ResetJobBookmark", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("JobName"=>JobName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    resume_workflow_run(name, node_ids, run_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Restarts selected nodes of a previous partially completed workflow run and resumes the
workflow run. The selected nodes and all nodes that are downstream from the selected nodes
are run.

# Arguments
- `name`: The name of the workflow to resume.
- `node_ids`: A list of the node IDs for the nodes you want to restart. The nodes that are
  to be restarted must have a run attempt in the original run.
- `run_id`: The ID of the workflow run to resume.

"""
function resume_workflow_run(Name, NodeIds, RunId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("ResumeWorkflowRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name, "NodeIds"=>NodeIds, "RunId"=>RunId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    search_tables(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Searches a set of tables based on properties in the table metadata as well as on the parent
database. You can search against text or filter conditions.  You can only get tables that
you have access to based on the security policies defined in Lake Formation. You need at
least a read-only access to the table for it to be returned. If you do not have access to
all the columns in the table, these columns will not be searched against when returning the
list of tables back to you. If you have access to the columns but not the data in the
columns, those columns and the associated metadata for those columns will be included in
the search.

# Keyword Parameters
- `catalog_id`: A unique identifier, consisting of  account_id .
- `filters`: A list of key-value pairs, and a comparator used to filter the search results.
  Returns all entities matching the predicate. The Comparator member of the PropertyPredicate
  struct is used only for time fields, and can be omitted for other field types. Also, when
  comparing string values, such as when Key=Name, a fuzzy match algorithm is used. The Key
  field (for example, the value of the Name field) is split on certain punctuation
  characters, for example, -, :, #, etc. into tokens. Then each token is exact-match compared
  with the Value member of PropertyPredicate. For example, if Key=Name and Value=link, tables
  named customer-link and xx-link-yy are returned, but xxlinkyy is not returned.
- `max_results`: The maximum number of tables to return in a single response.
- `next_token`: A continuation token, included if this is a continuation call.
- `resource_share_type`: Allows you to specify that you want to search the tables shared
  with your account. The allowable values are FOREIGN or ALL.    If set to FOREIGN, will
  search the tables shared with your account.    If set to ALL, will search the tables shared
  with your account, as well as the tables in yor local account.
- `search_text`: A string used for a text search. Specifying a value in quotes filters
  based on an exact match to the value.
- `sort_criteria`: A list of criteria for sorting the results by a field name, in an
  ascending or descending order.
"""
function search_tables(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("SearchTables", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    start_blueprint_run(blueprint_name, role_arn; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Starts a new run of the specified blueprint.

# Arguments
- `blueprint_name`: The name of the blueprint.
- `role_arn`: Specifies the IAM role used to create the workflow.

# Keyword Parameters
- `parameters`: Specifies the parameters as a BlueprintParameters object.
"""
function start_blueprint_run(BlueprintName, RoleArn; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StartBlueprintRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("BlueprintName"=>BlueprintName, "RoleArn"=>RoleArn), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    start_crawler(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Starts a crawl using the specified crawler, regardless of what is scheduled. If the crawler
is already running, returns a CrawlerRunningException.

# Arguments
- `name`: Name of the crawler to start.

"""
function start_crawler(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StartCrawler", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    start_crawler_schedule(crawler_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Changes the schedule state of the specified crawler to SCHEDULED, unless the crawler is
already running or the schedule state is already SCHEDULED.

# Arguments
- `crawler_name`: Name of the crawler to schedule.

"""
function start_crawler_schedule(CrawlerName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StartCrawlerSchedule", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("CrawlerName"=>CrawlerName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    start_export_labels_task_run(output_s3_path, transform_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Begins an asynchronous task to export all labeled data for a particular transform. This
task is the only label-related API call that is not part of the typical active learning
workflow. You typically use StartExportLabelsTaskRun when you want to work with all of your
existing labels at the same time, such as when you want to remove or change labels that
were previously submitted as truth. This API operation accepts the TransformId whose labels
you want to export and an Amazon Simple Storage Service (Amazon S3) path to export the
labels to. The operation returns a TaskRunId. You can check on the status of your task run
by calling the GetMLTaskRun API.

# Arguments
- `output_s3_path`: The Amazon S3 path where you export the labels.
- `transform_id`: The unique identifier of the machine learning transform.

"""
function start_export_labels_task_run(OutputS3Path, TransformId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StartExportLabelsTaskRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("OutputS3Path"=>OutputS3Path, "TransformId"=>TransformId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    start_import_labels_task_run(input_s3_path, transform_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Enables you to provide additional labels (examples of truth) to be used to teach the
machine learning transform and improve its quality. This API operation is generally used as
part of the active learning workflow that starts with the
StartMLLabelingSetGenerationTaskRun call and that ultimately results in improving the
quality of your machine learning transform.  After the StartMLLabelingSetGenerationTaskRun
finishes, Glue machine learning will have generated a series of questions for humans to
answer. (Answering these questions is often called 'labeling' in the machine learning
workflows). In the case of the FindMatches transform, these questions are of the form,
“What is the correct way to group these rows together into groups composed entirely of
matching records?” After the labeling process is finished, users upload their
answers/labels with a call to StartImportLabelsTaskRun. After StartImportLabelsTaskRun
finishes, all future runs of the machine learning transform use the new and improved labels
and perform a higher-quality transformation. By default,
StartMLLabelingSetGenerationTaskRun continually learns from and combines all labels that
you upload unless you set Replace to true. If you set Replace to true,
StartImportLabelsTaskRun deletes and forgets all previously uploaded labels and learns only
from the exact set that you upload. Replacing labels can be helpful if you realize that you
previously uploaded incorrect labels, and you believe that they are having a negative
effect on your transform quality. You can check on the status of your task run by calling
the GetMLTaskRun operation.

# Arguments
- `input_s3_path`: The Amazon Simple Storage Service (Amazon S3) path from where you import
  the labels.
- `transform_id`: The unique identifier of the machine learning transform.

# Keyword Parameters
- `replace_all_labels`: Indicates whether to overwrite your existing labels.
"""
function start_import_labels_task_run(InputS3Path, TransformId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StartImportLabelsTaskRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("InputS3Path"=>InputS3Path, "TransformId"=>TransformId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    start_job_run(job_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Starts a job run using a job definition.

# Arguments
- `job_name`: The name of the job definition to use.

# Keyword Parameters
- `allocated_capacity`: This field is deprecated. Use MaxCapacity instead. The number of
  Glue data processing units (DPUs) to allocate to this JobRun. From 2 to 100 DPUs can be
  allocated; the default is 10. A DPU is a relative measure of processing power that consists
  of 4 vCPUs of compute capacity and 16 GB of memory. For more information, see the Glue
  pricing page.
- `arguments`: The job arguments specifically for this run. For this job run, they replace
  the default arguments set in the job definition itself. You can specify arguments here that
  your own job-execution script consumes, as well as arguments that Glue itself consumes. For
  information about how to specify and consume your own Job arguments, see the Calling Glue
  APIs in Python topic in the developer guide. For information about the key-value pairs that
  Glue consumes to set up your job, see the Special Parameters Used by Glue topic in the
  developer guide.
- `job_run_id`: The ID of a previous JobRun to retry.
- `max_capacity`: The number of Glue data processing units (DPUs) that can be allocated
  when this job runs. A DPU is a relative measure of processing power that consists of 4
  vCPUs of compute capacity and 16 GB of memory. For more information, see the Glue pricing
  page. Do not set Max Capacity if using WorkerType and NumberOfWorkers. The value that can
  be allocated for MaxCapacity depends on whether you are running a Python shell job, or an
  Apache Spark ETL job:   When you specify a Python shell job
  (JobCommand.Name=\"pythonshell\"), you can allocate either 0.0625 or 1 DPU. The default is
  0.0625 DPU.   When you specify an Apache Spark ETL job (JobCommand.Name=\"glueetl\"), you
  can allocate from 2 to 100 DPUs. The default is 10 DPUs. This job type cannot have a
  fractional DPU allocation.
- `notification_property`: Specifies configuration properties of a job run notification.
- `number_of_workers`: The number of workers of a defined workerType that are allocated
  when a job runs. The maximum number of workers you can define are 299 for G.1X, and 149 for
  G.2X.
- `security_configuration`: The name of the SecurityConfiguration structure to be used with
  this job run.
- `timeout`: The JobRun timeout in minutes. This is the maximum time that a job run can
  consume resources before it is terminated and enters TIMEOUT status. The default is 2,880
  minutes (48 hours). This overrides the timeout value set in the parent job.
- `worker_type`: The type of predefined worker that is allocated when a job runs. Accepts a
  value of Standard, G.1X, or G.2X.   For the Standard worker type, each worker provides 4
  vCPU, 16 GB of memory and a 50GB disk, and 2 executors per worker.   For the G.1X worker
  type, each worker provides 4 vCPU, 16 GB of memory and a 64GB disk, and 1 executor per
  worker.   For the G.2X worker type, each worker provides 8 vCPU, 32 GB of memory and a
  128GB disk, and 1 executor per worker.
"""
function start_job_run(JobName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StartJobRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("JobName"=>JobName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    start_mlevaluation_task_run(transform_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Starts a task to estimate the quality of the transform.  When you provide label sets as
examples of truth, Glue machine learning uses some of those examples to learn from them.
The rest of the labels are used as a test to estimate quality. Returns a unique identifier
for the run. You can call GetMLTaskRun to get more information about the stats of the
EvaluationTaskRun.

# Arguments
- `transform_id`: The unique identifier of the machine learning transform.

"""
function start_mlevaluation_task_run(TransformId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StartMLEvaluationTaskRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("TransformId"=>TransformId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    start_mllabeling_set_generation_task_run(output_s3_path, transform_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Starts the active learning workflow for your machine learning transform to improve the
transform's quality by generating label sets and adding labels. When the
StartMLLabelingSetGenerationTaskRun finishes, Glue will have generated a \"labeling set\"
or a set of questions for humans to answer. In the case of the FindMatches transform, these
questions are of the form, “What is the correct way to group these rows together into
groups composed entirely of matching records?”  After the labeling process is finished,
you can upload your labels with a call to StartImportLabelsTaskRun. After
StartImportLabelsTaskRun finishes, all future runs of the machine learning transform will
use the new and improved labels and perform a higher-quality transformation.

# Arguments
- `output_s3_path`: The Amazon Simple Storage Service (Amazon S3) path where you generate
  the labeling set.
- `transform_id`: The unique identifier of the machine learning transform.

"""
function start_mllabeling_set_generation_task_run(OutputS3Path, TransformId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StartMLLabelingSetGenerationTaskRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("OutputS3Path"=>OutputS3Path, "TransformId"=>TransformId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    start_trigger(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Starts an existing trigger. See Triggering Jobs for information about how different types
of trigger are started.

# Arguments
- `name`: The name of the trigger to start.

"""
function start_trigger(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StartTrigger", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    start_workflow_run(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Starts a new run of the specified workflow.

# Arguments
- `name`: The name of the workflow to start.

"""
function start_workflow_run(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StartWorkflowRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    stop_crawler(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

If the specified crawler is running, stops the crawl.

# Arguments
- `name`: Name of the crawler to stop.

"""
function stop_crawler(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StopCrawler", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    stop_crawler_schedule(crawler_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Sets the schedule state of the specified crawler to NOT_SCHEDULED, but does not stop the
crawler if it is already running.

# Arguments
- `crawler_name`: Name of the crawler whose schedule state to set.

"""
function stop_crawler_schedule(CrawlerName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StopCrawlerSchedule", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("CrawlerName"=>CrawlerName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    stop_trigger(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Stops a specified trigger.

# Arguments
- `name`: The name of the trigger to stop.

"""
function stop_trigger(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StopTrigger", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    stop_workflow_run(name, run_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Stops the execution of the specified workflow run.

# Arguments
- `name`: The name of the workflow to stop.
- `run_id`: The ID of the workflow run to stop.

"""
function stop_workflow_run(Name, RunId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("StopWorkflowRun", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name, "RunId"=>RunId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    tag_resource(resource_arn, tags_to_add; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Adds tags to a resource. A tag is a label you can assign to an Amazon Web Services
resource. In Glue, you can tag only certain resources. For information about what resources
you can tag, see Amazon Web Services Tags in Glue.

# Arguments
- `resource_arn`: The ARN of the Glue resource to which to add the tags. For more
  information about Glue resource ARNs, see the Glue ARN string pattern.
- `tags_to_add`: Tags to add to this resource.

"""
function tag_resource(ResourceArn, TagsToAdd; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("TagResource", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ResourceArn"=>ResourceArn, "TagsToAdd"=>TagsToAdd), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    untag_resource(resource_arn, tags_to_remove; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Removes tags from a resource.

# Arguments
- `resource_arn`: The Amazon Resource Name (ARN) of the resource from which to remove the
  tags.
- `tags_to_remove`: Tags to remove from this resource.

"""
function untag_resource(ResourceArn, TagsToRemove; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UntagResource", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ResourceArn"=>ResourceArn, "TagsToRemove"=>TagsToRemove), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_blueprint(blueprint_location, name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates a registered blueprint.

# Arguments
- `blueprint_location`: Specifies a path in Amazon S3 where the blueprint is published.
- `name`: The name of the blueprint.

# Keyword Parameters
- `description`: A description of the blueprint.
"""
function update_blueprint(BlueprintLocation, Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateBlueprint", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("BlueprintLocation"=>BlueprintLocation, "Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_classifier(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Modifies an existing classifier (a GrokClassifier, an XMLClassifier, a JsonClassifier, or a
CsvClassifier, depending on which field is present).

# Keyword Parameters
- `csv_classifier`: A CsvClassifier object with updated fields.
- `grok_classifier`: A GrokClassifier object with updated fields.
- `json_classifier`: A JsonClassifier object with updated fields.
- `xmlclassifier`: An XMLClassifier object with updated fields.
"""
function update_classifier(; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateClassifier", params; aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_column_statistics_for_partition(column_statistics_list, database_name, partition_values, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates or updates partition statistics of columns. The Identity and Access Management
(IAM) permission required for this operation is UpdatePartition.

# Arguments
- `column_statistics_list`: A list of the column statistics.
- `database_name`: The name of the catalog database where the partitions reside.
- `partition_values`: A list of partition values identifying the partition.
- `table_name`: The name of the partitions' table.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the partitions in question reside. If none
  is supplied, the Amazon Web Services account ID is used by default.
"""
function update_column_statistics_for_partition(ColumnStatisticsList, DatabaseName, PartitionValues, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateColumnStatisticsForPartition", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ColumnStatisticsList"=>ColumnStatisticsList, "DatabaseName"=>DatabaseName, "PartitionValues"=>PartitionValues, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_column_statistics_for_table(column_statistics_list, database_name, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Creates or updates table statistics of columns. The Identity and Access Management (IAM)
permission required for this operation is UpdateTable.

# Arguments
- `column_statistics_list`: A list of the column statistics.
- `database_name`: The name of the catalog database where the partitions reside.
- `table_name`: The name of the partitions' table.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the partitions in question reside. If none
  is supplied, the Amazon Web Services account ID is used by default.
"""
function update_column_statistics_for_table(ColumnStatisticsList, DatabaseName, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateColumnStatisticsForTable", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ColumnStatisticsList"=>ColumnStatisticsList, "DatabaseName"=>DatabaseName, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_connection(connection_input, name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates a connection definition in the Data Catalog.

# Arguments
- `connection_input`: A ConnectionInput object that redefines the connection in question.
- `name`: The name of the connection definition to update.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog in which the connection resides. If none is
  provided, the Amazon Web Services account ID is used by default.
"""
function update_connection(ConnectionInput, Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateConnection", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("ConnectionInput"=>ConnectionInput, "Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_crawler(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates a crawler. If a crawler is running, you must stop it using StopCrawler before
updating it.

# Arguments
- `name`: Name of the new crawler.

# Keyword Parameters
- `classifiers`: A list of custom classifiers that the user has registered. By default, all
  built-in classifiers are included in a crawl, but these custom classifiers always override
  the default classifiers for a given classification.
- `configuration`: Crawler configuration information. This versioned JSON string allows
  users to specify aspects of a crawler's behavior. For more information, see Configuring a
  Crawler.
- `crawler_security_configuration`: The name of the SecurityConfiguration structure to be
  used by this crawler.
- `database_name`: The Glue database where results are stored, such as:
  arn:aws:daylight:us-east-1::database/sometable/*.
- `description`: A description of the new crawler.
- `lineage_configuration`: Specifies data lineage configuration settings for the crawler.
- `recrawl_policy`: A policy that specifies whether to crawl the entire dataset again, or
  to crawl only folders that were added since the last crawler run.
- `role`: The IAM role or Amazon Resource Name (ARN) of an IAM role that is used by the new
  crawler to access customer resources.
- `schedule`: A cron expression used to specify the schedule (see Time-Based Schedules for
  Jobs and Crawlers. For example, to run something every day at 12:15 UTC, you would specify:
  cron(15 12 * * ? *).
- `schema_change_policy`: The policy for the crawler's update and deletion behavior.
- `table_prefix`: The table prefix used for catalog tables that are created.
- `targets`: A list of targets to crawl.
"""
function update_crawler(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateCrawler", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_crawler_schedule(crawler_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates the schedule of a crawler using a cron expression.

# Arguments
- `crawler_name`: The name of the crawler whose schedule to update.

# Keyword Parameters
- `schedule`: The updated cron expression used to specify the schedule (see Time-Based
  Schedules for Jobs and Crawlers. For example, to run something every day at 12:15 UTC, you
  would specify: cron(15 12 * * ? *).
"""
function update_crawler_schedule(CrawlerName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateCrawlerSchedule", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("CrawlerName"=>CrawlerName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_database(database_input, name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates an existing database definition in a Data Catalog.

# Arguments
- `database_input`: A DatabaseInput object specifying the new definition of the metadata
  database in the catalog.
- `name`: The name of the database to update in the catalog. For Hive compatibility, this
  is folded to lowercase.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog in which the metadata database resides. If none
  is provided, the Amazon Web Services account ID is used by default.
"""
function update_database(DatabaseInput, Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateDatabase", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseInput"=>DatabaseInput, "Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_dev_endpoint(endpoint_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates a specified development endpoint.

# Arguments
- `endpoint_name`: The name of the DevEndpoint to be updated.

# Keyword Parameters
- `add_arguments`: The map of arguments to add the map of arguments used to configure the
  DevEndpoint. Valid arguments are:    \"--enable-glue-datacatalog\": \"\"    You can specify
  a version of Python support for development endpoints by using the Arguments parameter in
  the CreateDevEndpoint or UpdateDevEndpoint APIs. If no arguments are provided, the version
  defaults to Python 2.
- `add_public_keys`: The list of public keys for the DevEndpoint to use.
- `custom_libraries`: Custom Python or Java libraries to be loaded in the DevEndpoint.
- `delete_arguments`: The list of argument keys to be deleted from the map of arguments
  used to configure the DevEndpoint.
- `delete_public_keys`: The list of public keys to be deleted from the DevEndpoint.
- `public_key`: The public key for the DevEndpoint to use.
- `update_etl_libraries`:  True if the list of custom libraries to be loaded in the
  development endpoint needs to be updated, or False if otherwise.
"""
function update_dev_endpoint(EndpointName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateDevEndpoint", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("EndpointName"=>EndpointName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_job(job_name, job_update; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates an existing job definition.

# Arguments
- `job_name`: The name of the job definition to update.
- `job_update`: Specifies the values with which to update the job definition.

"""
function update_job(JobName, JobUpdate; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateJob", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("JobName"=>JobName, "JobUpdate"=>JobUpdate), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_mltransform(transform_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates an existing machine learning transform. Call this operation to tune the algorithm
parameters to achieve better results. After calling this operation, you can call the
StartMLEvaluationTaskRun operation to assess how well your new parameters achieved your
goals (such as improving the quality of your machine learning transform, or making it more
cost-effective).

# Arguments
- `transform_id`: A unique identifier that was generated when the transform was created.

# Keyword Parameters
- `description`: A description of the transform. The default is an empty string.
- `glue_version`: This value determines which version of Glue this machine learning
  transform is compatible with. Glue 1.0 is recommended for most customers. If the value is
  not set, the Glue compatibility defaults to Glue 0.9. For more information, see Glue
  Versions in the developer guide.
- `max_capacity`: The number of Glue data processing units (DPUs) that are allocated to
  task runs for this transform. You can allocate from 2 to 100 DPUs; the default is 10. A DPU
  is a relative measure of processing power that consists of 4 vCPUs of compute capacity and
  16 GB of memory. For more information, see the Glue pricing page.  When the WorkerType
  field is set to a value other than Standard, the MaxCapacity field is set automatically and
  becomes read-only.
- `max_retries`: The maximum number of times to retry a task for this transform after a
  task run fails.
- `name`: The unique name that you gave the transform when you created it.
- `number_of_workers`: The number of workers of a defined workerType that are allocated
  when this task runs.
- `parameters`: The configuration parameters that are specific to the transform type
  (algorithm) used. Conditionally dependent on the transform type.
- `role`: The name or Amazon Resource Name (ARN) of the IAM role with the required
  permissions.
- `timeout`: The timeout for a task run for this transform in minutes. This is the maximum
  time that a task run for this transform can consume resources before it is terminated and
  enters TIMEOUT status. The default is 2,880 minutes (48 hours).
- `worker_type`: The type of predefined worker that is allocated when this task runs.
  Accepts a value of Standard, G.1X, or G.2X.   For the Standard worker type, each worker
  provides 4 vCPU, 16 GB of memory and a 50GB disk, and 2 executors per worker.   For the
  G.1X worker type, each worker provides 4 vCPU, 16 GB of memory and a 64GB disk, and 1
  executor per worker.   For the G.2X worker type, each worker provides 8 vCPU, 32 GB of
  memory and a 128GB disk, and 1 executor per worker.
"""
function update_mltransform(TransformId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateMLTransform", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("TransformId"=>TransformId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_partition(database_name, partition_input, partition_value_list, table_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates a partition.

# Arguments
- `database_name`: The name of the catalog database in which the table in question resides.
- `partition_input`: The new partition object to update the partition to. The Values
  property can't be changed. If you want to change the partition key values for a partition,
  delete and recreate the partition.
- `partition_value_list`: List of partition key values that define the partition to update.
- `table_name`: The name of the table in which the partition to be updated is located.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the partition to be updated resides. If
  none is provided, the Amazon Web Services account ID is used by default.
"""
function update_partition(DatabaseName, PartitionInput, PartitionValueList, TableName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdatePartition", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "PartitionInput"=>PartitionInput, "PartitionValueList"=>PartitionValueList, "TableName"=>TableName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_registry(description, registry_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates an existing registry which is used to hold a collection of schemas. The updated
properties relate to the registry, and do not modify any of the schemas within the
registry.

# Arguments
- `description`: A description of the registry. If description is not provided, this field
  will not be updated.
- `registry_id`: This is a wrapper structure that may contain the registry name and Amazon
  Resource Name (ARN).

"""
function update_registry(Description, RegistryId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateRegistry", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Description"=>Description, "RegistryId"=>RegistryId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_schema(schema_id; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates the description, compatibility setting, or version checkpoint for a schema set. For
updating the compatibility setting, the call will not validate compatibility for the entire
set of schema versions with the new compatibility setting. If the value for Compatibility
is provided, the VersionNumber (a checkpoint) is also required. The API will validate the
checkpoint version number for consistency. If the value for the VersionNumber (checkpoint)
is provided, Compatibility is optional and this can be used to set/reset a checkpoint for
the schema. This update will happen only if the schema is in the AVAILABLE state.

# Arguments
- `schema_id`: This is a wrapper structure to contain schema identity fields. The structure
  contains:   SchemaIdSchemaArn: The Amazon Resource Name (ARN) of the schema. One of
  SchemaArn or SchemaName has to be provided.   SchemaIdSchemaName: The name of the schema.
  One of SchemaArn or SchemaName has to be provided.

# Keyword Parameters
- `compatibility`: The new compatibility setting for the schema.
- `description`: The new description for the schema.
- `schema_version_number`: Version number required for check pointing. One of VersionNumber
  or Compatibility has to be provided.
"""
function update_schema(SchemaId; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateSchema", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("SchemaId"=>SchemaId), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_table(database_name, table_input; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates a metadata table in the Data Catalog.

# Arguments
- `database_name`: The name of the catalog database in which the table resides. For Hive
  compatibility, this name is entirely lowercase.
- `table_input`: An updated TableInput object to define the metadata table in the catalog.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the table resides. If none is provided,
  the Amazon Web Services account ID is used by default.
- `skip_archive`: By default, UpdateTable always creates an archived version of the table
  before updating it. However, if skipArchive is set to true, UpdateTable does not create the
  archived version.
"""
function update_table(DatabaseName, TableInput; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateTable", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "TableInput"=>TableInput), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_trigger(name, trigger_update; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates a trigger definition.

# Arguments
- `name`: The name of the trigger to update.
- `trigger_update`: The new values with which to update the trigger.

"""
function update_trigger(Name, TriggerUpdate; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateTrigger", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name, "TriggerUpdate"=>TriggerUpdate), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_user_defined_function(database_name, function_input, function_name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates an existing function definition in the Data Catalog.

# Arguments
- `database_name`: The name of the catalog database where the function to be updated is
  located.
- `function_input`: A FunctionInput object that redefines the function in the Data Catalog.
- `function_name`: The name of the function.

# Keyword Parameters
- `catalog_id`: The ID of the Data Catalog where the function to be updated is located. If
  none is provided, the Amazon Web Services account ID is used by default.
"""
function update_user_defined_function(DatabaseName, FunctionInput, FunctionName; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateUserDefinedFunction", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("DatabaseName"=>DatabaseName, "FunctionInput"=>FunctionInput, "FunctionName"=>FunctionName), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end

"""
    update_workflow(name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)

Updates an existing workflow.

# Arguments
- `name`: Name of the workflow to be updated.

# Keyword Parameters
- `default_run_properties`: A collection of properties to be used as part of each execution
  of the workflow.
- `description`: The description of the workflow.
- `max_concurrent_runs`: You can use this parameter to prevent unwanted multiple updates to
  data, to control costs, or in some cases, to prevent exceeding the maximum number of
  concurrent runs of any of the component jobs. If you leave this parameter blank, there is
  no limit to the number of concurrent workflow runs.
"""
function update_workflow(Name; aws_config::AbstractAWSConfig=global_aws_config(), kwargs...)
    params = amazonify(MAPPING, kwargs)
    return glue("UpdateWorkflow", Dict{String, Any}(mergewith(_merge, Dict{String, Any}("Name"=>Name), params)); aws_config=aws_config, feature_set=SERVICE_FEATURE_SET)
end
